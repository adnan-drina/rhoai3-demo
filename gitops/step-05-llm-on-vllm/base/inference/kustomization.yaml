apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

# InferenceServices for Mistral-Small-24B
# Two deployments demonstrating FP8 efficiency on NVIDIA L4

resources:
  # Full precision (BF16) - 4 GPUs with tensor parallelism
  - mistral-24b-full.yaml
  # FP8 quantized - 1 GPU (Neural Magic optimized)
  - mistral-24b-fp8.yaml
