# =============================================================================
# GPU Switchboard Workbench - RHOAI 3.0 OAuth-Proxy Sidecar Pattern
# =============================================================================
# Aligned with official Red Hat documentation:
# https://docs.redhat.com/en/documentation/red_hat_openshift_ai_self-managed/3.0/html-single/creating_a_workbench/index
#
# This pattern uses the oauth-proxy sidecar container for authentication:
#   - Jupyter notebook on port 8888 (internal only)
#   - OAuth-proxy sidecar on port 8443 (external HTTPS)
#   - TLS termination handled by oauth-proxy (not Gateway)
#
# Required Secrets (auto-generated by this manifest):
#   - gpu-switchboard-oauth-config: Cookie secret for OAuth sessions
#   - gpu-switchboard-tls: Serving certificate (via OpenShift annotation)
# =============================================================================

# -----------------------------------------------------------------------------
# ServiceAccount: Workbench Identity (Required by oauth-proxy)
# -----------------------------------------------------------------------------
apiVersion: v1
kind: ServiceAccount
metadata:
  name: gpu-switchboard
  namespace: private-ai
  labels:
    app: gpu-switchboard
    opendatahub.io/dashboard: "true"
  annotations:
    argocd.argoproj.io/sync-wave: "5"
    # OpenShift will automatically create the OAuth client for this SA
    serviceaccounts.openshift.io/oauth-redirectreference.primary: '{"kind":"OAuthRedirectReference","apiVersion":"v1","reference":{"kind":"Route","name":"gpu-switchboard"}}'
---
# -----------------------------------------------------------------------------
# PVC: Workbench Storage
# -----------------------------------------------------------------------------
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: gpu-switchboard-storage
  namespace: private-ai
  labels:
    app: gpu-switchboard
    opendatahub.io/dashboard: "true"
  annotations:
    argocd.argoproj.io/sync-wave: "5"
    openshift.io/display-name: gpu-switchboard-storage
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 20Gi
  storageClassName: gp3-csi
---
# -----------------------------------------------------------------------------
# Secret: OAuth Cookie Configuration
# -----------------------------------------------------------------------------
# Cookie secret for OAuth session management.
# This is a base64-encoded random string (24 bytes recommended).
# In production, generate with: openssl rand -base64 24
apiVersion: v1
kind: Secret
metadata:
  name: gpu-switchboard-oauth-config
  namespace: private-ai
  labels:
    app: gpu-switchboard
  annotations:
    argocd.argoproj.io/sync-wave: "5"
type: Opaque
stringData:
  cookie_secret: "R3B1U3dpdGNoYm9hcmRDb29raWVTZWNyZXQ="
---
# =============================================================================
# PostSync Hook: Fix Controller Service Port Mismatch (Gateway API Bug)
# =============================================================================
# RHOAI 3.0 BUG: The Notebook Controller creates HTTPRoutes targeting port 8888,
# but its Service reconciler creates Services exposing port 80.
#
# This causes the Gateway API URL (shown in Dashboard) to fail after OAuth.
# The Gateway tries Service:8888 but Service only exposes 80.
#
# FIX: Patch the controller-managed Service to expose port 8888 after every sync.
# This makes BOTH URLs work:
#   - Dashboard URL (Gateway API): https://data-science-gateway.../notebook/...
#   - Custom Route URL: https://gpu-switchboard-private-ai.../notebook/...
# =============================================================================
apiVersion: v1
kind: ServiceAccount
metadata:
  name: service-patcher
  namespace: private-ai
  annotations:
    argocd.argoproj.io/hook: PostSync
    argocd.argoproj.io/hook-delete-policy: HookSucceeded
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: service-patcher
  namespace: private-ai
  annotations:
    argocd.argoproj.io/hook: PostSync
    argocd.argoproj.io/hook-delete-policy: HookSucceeded
rules:
  - apiGroups: [""]
    resources: ["services"]
    verbs: ["get", "patch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: service-patcher
  namespace: private-ai
  annotations:
    argocd.argoproj.io/hook: PostSync
    argocd.argoproj.io/hook-delete-policy: HookSucceeded
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: service-patcher
subjects:
  - kind: ServiceAccount
    name: service-patcher
    namespace: private-ai
---
apiVersion: batch/v1
kind: Job
metadata:
  name: fix-gpu-switchboard-service
  namespace: private-ai
  annotations:
    argocd.argoproj.io/hook: PostSync
    argocd.argoproj.io/hook-delete-policy: HookSucceeded
spec:
  ttlSecondsAfterFinished: 60
  template:
    spec:
      serviceAccountName: service-patcher
      restartPolicy: OnFailure
      containers:
        - name: patcher
          image: registry.redhat.io/openshift4/ose-cli:latest
          command:
            - /bin/bash
            - -c
            - |
              echo "╔═══════════════════════════════════════════════════════════════╗"
              echo "║  RHOAI 3.0 Gateway API Fix: Patching Service to port 8888     ║"
              echo "╚═══════════════════════════════════════════════════════════════╝"
              
              # Wait for controller-managed Service to exist
              for i in {1..30}; do
                if oc get svc gpu-switchboard -n private-ai &>/dev/null; then
                  break
                fi
                echo "Waiting for Service... ($i/30)"
                sleep 2
              done
              
              # Patch Service to expose port 8888 (matching HTTPRoute target)
              oc patch svc gpu-switchboard -n private-ai --type=json -p='[
                {"op": "replace", "path": "/spec/ports/0/port", "value": 8888},
                {"op": "replace", "path": "/spec/ports/0/name", "value": "http-notebook"}
              ]'
              
              # Verify
              PORT=$(oc get svc gpu-switchboard -n private-ai -o jsonpath='{.spec.ports[0].port}')
              if [ "$PORT" == "8888" ]; then
                echo "✅ Service patched: port 80 → 8888"
                echo "✅ Dashboard URL will now work!"
              else
                echo "❌ Failed to patch Service (port: $PORT)"
                exit 1
              fi
---
# -----------------------------------------------------------------------------
# Service: GPU Switchboard OAuth (SEPARATE from controller-managed Service)
# -----------------------------------------------------------------------------
# IMPORTANT: The Notebook Controller automatically creates and manages a Service
# named "gpu-switchboard" that targets port 8888. We CANNOT override this.
#
# SOLUTION: Create a SEPARATE Service with a different name that targets the
# oauth-proxy sidecar on port 8443. The Route uses this Service.
#
# This is the only persistent solution because:
#   - Controller-managed Service: "gpu-switchboard" -> port 80/8888 (notebook)
#   - GitOps-managed Service: "gpu-switchboard-oauth" -> port 8443 (oauth-proxy)
# -----------------------------------------------------------------------------
apiVersion: v1
kind: Service
metadata:
  name: gpu-switchboard-oauth
  namespace: private-ai
  labels:
    app: gpu-switchboard
  annotations:
    argocd.argoproj.io/sync-wave: "8"
    # OpenShift serving certificate - generates TLS secret for THIS service name
    service.beta.openshift.io/serving-cert-secret-name: gpu-switchboard-oauth-tls
spec:
  ports:
    - name: oauth-proxy
      port: 8443
      protocol: TCP
      targetPort: 8443
  selector:
    statefulset: gpu-switchboard
  type: ClusterIP
---
# -----------------------------------------------------------------------------
# Route: GPU Switchboard (via OAuth-Proxy Service)
# -----------------------------------------------------------------------------
# Uses reencrypt TLS:
#   - Router terminates external TLS
#   - Re-encrypts to oauth-proxy (which has OpenShift-generated TLS cert)
#   - oauth-proxy handles OpenShift OAuth and proxies to Jupyter
#
# This Route uses the SEPARATE "gpu-switchboard-oauth" Service that the
# Notebook Controller does NOT manage.
# -----------------------------------------------------------------------------
apiVersion: route.openshift.io/v1
kind: Route
metadata:
  name: gpu-switchboard
  namespace: private-ai
  labels:
    app: gpu-switchboard
  annotations:
    argocd.argoproj.io/sync-wave: "9"
spec:
  to:
    kind: Service
    name: gpu-switchboard-oauth
    weight: 100
  port:
    targetPort: oauth-proxy
  tls:
    termination: reencrypt
    insecureEdgeTerminationPolicy: Redirect
  wildcardPolicy: None
---
# -----------------------------------------------------------------------------
# Notebook: GPU Switchboard with OAuth-Proxy Sidecar
# -----------------------------------------------------------------------------
# Following official RHOAI 3.0 documentation pattern exactly:
# https://docs.redhat.com/en/documentation/red_hat_openshift_ai_self-managed/3.0/html-single/creating_a_workbench/index
# -----------------------------------------------------------------------------
apiVersion: kubeflow.org/v1
kind: Notebook
metadata:
  name: gpu-switchboard
  namespace: private-ai
  labels:
    app: gpu-switchboard
    opendatahub.io/dashboard: "true"
    opendatahub.io/odh-managed: "true"
  annotations:
    argocd.argoproj.io/sync-wave: "10"
    # OAuth injection - tells controller we're handling OAuth manually
    notebooks.opendatahub.io/inject-oauth: "true"
    # OAuth logout URL (matches documentation)
    notebooks.opendatahub.io/oauth-logout-url: "https://rhods-dashboard-redhat-ods-applications.apps.cluster-78cqq.78cqq.sandbox3352.opentlc.com/projects/private-ai?notebookLogout=gpu-switchboard"
    # Hardware Profile: Delegates resource management to the platform
    opendatahub.io/hardware-profile-name: cpu-small
    opendatahub.io/hardware-profile-namespace: redhat-ods-applications
    # UI Metadata
    opendatahub.io/image-display-name: "Jupyter | Data Science | CPU | Python 3.12"
    opendatahub.io/username: ai-admin
    notebooks.opendatahub.io/last-image-selection: s2i-generic-data-science-notebook:2025.2
    notebooks.opendatahub.io/last-image-version-git-commit-selection: d3137ca
    notebooks.opendatahub.io/last-size-selection: Small
    openshift.io/display-name: "GPU Switchboard"
    openshift.io/description: "Interactive notebook for GPU-as-a-Service demo - control 5 models with CLI commands"
spec:
  template:
    spec:
      enableServiceLinks: false
      serviceAccountName: gpu-switchboard
      affinity: {}
      # =========================================================================
      # Git-Sync Init Container
      # =========================================================================
      initContainers:
        - name: git-sync
          image: alpine/git:latest
          command:
            - /bin/sh
            - -c
            - |
              set -e
              REPO_URL="https://github.com/adnan-drina/rhoai3-demo.git"
              WORKSPACE="/opt/app-root/src"
              NOTEBOOKS_SRC="gitops/step-05-llm-on-vllm/base/controller"
              
              echo "╔══════════════════════════════════════════════════════════════╗"
              echo "║  Git-Sync: Loading GPU Orchestrator Notebook                 ║"
              echo "╚══════════════════════════════════════════════════════════════╝"
              
              if [ ! -f "$WORKSPACE/GPU-Orchestrator.ipynb" ]; then
                echo "→ Cloning repository..."
                git clone --depth 1 --single-branch "$REPO_URL" /tmp/repo
                
                echo "→ Copying notebooks to workspace..."
                cp /tmp/repo/$NOTEBOOKS_SRC/*.ipynb "$WORKSPACE/" 2>/dev/null || true
                
                rm -rf /tmp/repo
                echo "✓ Notebooks synced successfully!"
              else
                echo "✓ Notebooks already exist - skipping sync"
              fi
              
              ls -la "$WORKSPACE/"
          volumeMounts:
            - name: gpu-switchboard-storage
              mountPath: /opt/app-root/src
          resources:
            limits:
              cpu: 100m
              memory: 128Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop: ["ALL"]
      # =========================================================================
      # Containers: Jupyter + OAuth-Proxy (per RHOAI 3.0 documentation)
      # =========================================================================
      containers:
        # -----------------------------------------------------------------------
        # Container 1: Jupyter Notebook (port 8888, internal only)
        # -----------------------------------------------------------------------
        - name: gpu-switchboard
          image: image-registry.openshift-image-registry.svc:5000/redhat-ods-applications/s2i-generic-data-science-notebook:2025.2
          imagePullPolicy: Always
          workingDir: /opt/app-root/src
          env:
            - name: NOTEBOOK_ARGS
              value: |-
                --ServerApp.port=8888
                --ServerApp.token=''
                --ServerApp.password=''
                --ServerApp.base_url=/notebook/private-ai/gpu-switchboard
                --ServerApp.quit_button=False
                --ServerApp.tornado_settings={"user":"ai-admin","hub_host":"https://rhods-dashboard-redhat-ods-applications.apps.cluster-78cqq.78cqq.sandbox3352.opentlc.com","hub_prefix":"/projects/private-ai"}
            - name: JUPYTER_IMAGE
              value: image-registry.openshift-image-registry.svc:5000/redhat-ods-applications/s2i-generic-data-science-notebook:2025.2
            - name: PIP_CERT
              value: /etc/pki/tls/custom-certs/ca-bundle.crt
            - name: REQUESTS_CA_BUNDLE
              value: /etc/pki/tls/custom-certs/ca-bundle.crt
            - name: SSL_CERT_FILE
              value: /etc/pki/tls/custom-certs/ca-bundle.crt
            - name: PIPELINES_SSL_SA_CERTS
              value: /etc/pki/tls/custom-certs/ca-bundle.crt
            - name: GIT_SSL_CAINFO
              value: /etc/pki/tls/custom-certs/ca-bundle.crt
          ports:
            - containerPort: 8888
              name: notebook-port
              protocol: TCP
          resources:
            limits:
              cpu: "2"
              memory: 8Gi
            requests:
              cpu: "1"
              memory: 8Gi
          livenessProbe:
            httpGet:
              path: /notebook/private-ai/gpu-switchboard/api
              port: notebook-port
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 5
            timeoutSeconds: 1
            successThreshold: 1
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /notebook/private-ai/gpu-switchboard/api
              port: notebook-port
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 5
            timeoutSeconds: 1
            successThreshold: 1
            failureThreshold: 3
          volumeMounts:
            - name: gpu-switchboard-storage
              mountPath: /opt/app-root/src
            - name: shm
              mountPath: /dev/shm
            - name: trusted-ca
              mountPath: /etc/pki/tls/custom-certs/ca-bundle.crt
              subPath: ca-bundle.crt
              readOnly: true
        # -----------------------------------------------------------------------
        # Container 2: OAuth-Proxy Sidecar (port 8443, external HTTPS)
        # -----------------------------------------------------------------------
        # Per RHOAI 3.0 documentation: handles OpenShift OAuth authentication
        # https://docs.redhat.com/en/documentation/red_hat_openshift_ai_self-managed/3.0/html-single/creating_a_workbench/index
        # -----------------------------------------------------------------------
        - name: oauth-proxy
          image: registry.redhat.io/openshift4/ose-oauth-proxy-rhel9@sha256:ca21e218e26c46e3c63d926241846f8f307fd4a586cc4b04147da49af6018ef5
          imagePullPolicy: Always
          env:
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          args:
            - --provider=openshift
            - --https-address=:8443
            - --http-address=
            - --openshift-service-account=gpu-switchboard
            - --cookie-secret-file=/etc/oauth/config/cookie_secret
            - --cookie-expire=24h0m0s
            - --tls-cert=/etc/tls/private/tls.crt
            - --tls-key=/etc/tls/private/tls.key
            - --upstream=http://localhost:8888
            - --upstream-ca=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
            - --email-domain=*
            - --skip-provider-button
            - '--openshift-sar={"verb":"get","resource":"notebooks","resourceAPIGroup":"kubeflow.org","resourceName":"gpu-switchboard","namespace":"$(NAMESPACE)"}'
            - --logout-url=https://rhods-dashboard-redhat-ods-applications.apps.cluster-78cqq.78cqq.sandbox3352.opentlc.com/projects/private-ai?notebookLogout=gpu-switchboard
          ports:
            - containerPort: 8443
              name: oauth-proxy
              protocol: TCP
          resources:
            limits:
              cpu: 100m
              memory: 64Mi
            requests:
              cpu: 100m
              memory: 64Mi
          livenessProbe:
            httpGet:
              path: /oauth/healthz
              port: oauth-proxy
              scheme: HTTPS
            initialDelaySeconds: 30
            periodSeconds: 5
            timeoutSeconds: 1
            successThreshold: 1
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /oauth/healthz
              port: oauth-proxy
              scheme: HTTPS
            initialDelaySeconds: 5
            periodSeconds: 5
            timeoutSeconds: 1
            successThreshold: 1
            failureThreshold: 3
          volumeMounts:
            - name: oauth-config
              mountPath: /etc/oauth/config
            - name: tls-certificates
              mountPath: /etc/tls/private
      volumes:
        - name: gpu-switchboard-storage
          persistentVolumeClaim:
            claimName: gpu-switchboard-storage
        - name: shm
          emptyDir:
            medium: Memory
        - name: trusted-ca
          configMap:
            name: workbench-trusted-ca-bundle
            optional: true
            items:
              - key: ca-bundle.crt
                path: ca-bundle.crt
        - name: oauth-config
          secret:
            secretName: gpu-switchboard-oauth-config
            defaultMode: 420
        - name: tls-certificates
          secret:
            secretName: gpu-switchboard-oauth-tls
            defaultMode: 420
---
# =============================================================================
# NetworkPolicy: Allow Ingress from Gateway and Router
# =============================================================================
# CRITICAL: Must allow BOTH ports:
#   - Port 8888: Gateway API path (data-science-gateway → notebook directly)
#   - Port 8443: Custom Route path (Route → oauth-proxy sidecar)
# =============================================================================
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: gpu-switchboard-gateway-ingress
  namespace: private-ai
  labels:
    app: gpu-switchboard
  annotations:
    argocd.argoproj.io/sync-wave: "8"
spec:
  podSelector:
    matchLabels:
      notebook-name: gpu-switchboard
  policyTypes:
    - Ingress
  ingress:
    # Allow from OpenShift Router and Gateway (both ports)
    - from:
        - namespaceSelector:
            matchLabels:
              network.openshift.io/policy-group: ingress
      ports:
        - port: 8443
          protocol: TCP
        - port: 8888
          protocol: TCP
    # Allow from openshift-ingress namespace (Gateway)
    - from:
        - namespaceSelector:
            matchLabels:
              kubernetes.io/metadata.name: openshift-ingress
      ports:
        - port: 8443
          protocol: TCP
        - port: 8888
          protocol: TCP
---
# =============================================================================
# RBAC: GPU Switchboard Controller Permissions
# =============================================================================
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: gpu-switchboard-controller
  namespace: private-ai
  labels:
    app: gpu-switchboard
  annotations:
    argocd.argoproj.io/sync-wave: "5"
rules:
  # Deployments (RawDeployment mode - the primary way to scale InferenceServices)
  - apiGroups: ["apps"]
    resources: ["deployments"]
    verbs: ["get", "list", "watch", "patch", "update"]
  - apiGroups: ["apps"]
    resources: ["deployments/scale"]
    verbs: ["get", "patch", "update"]
  # InferenceService management (for metadata/status queries)
  - apiGroups: ["serving.kserve.io"]
    resources: ["inferenceservices"]
    verbs: ["get", "list", "watch", "patch", "update"]
  - apiGroups: ["serving.kserve.io"]
    resources: ["inferenceservices/scale"]
    verbs: ["get", "patch", "update"]
  # Knative services (ksvc) - not used in RawDeployment mode
  - apiGroups: ["serving.knative.dev"]
    resources: ["services"]
    verbs: ["get", "list", "watch", "patch", "update"]
  - apiGroups: ["serving.knative.dev"]
    resources: ["services/scale"]
    verbs: ["get", "patch", "update"]
  # Pod status
  - apiGroups: [""]
    resources: ["pods"]
    verbs: ["get", "list", "watch"]
  # Kueue workloads
  - apiGroups: ["kueue.x-k8s.io"]
    resources: ["workloads", "localqueues"]
    verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: gpu-switchboard-controller
  namespace: private-ai
  labels:
    app: gpu-switchboard
  annotations:
    argocd.argoproj.io/sync-wave: "5"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: gpu-switchboard-controller
subjects:
  - kind: ServiceAccount
    name: gpu-switchboard
    namespace: private-ai
---
# ClusterRole: View ClusterQueues
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: kueue-clusterqueue-viewer
  labels:
    app: gpu-switchboard
  annotations:
    argocd.argoproj.io/sync-wave: "5"
rules:
  - apiGroups: ["kueue.x-k8s.io"]
    resources: ["clusterqueues", "resourceflavors"]
    verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: gpu-switchboard-kueue-viewer
  labels:
    app: gpu-switchboard
  annotations:
    argocd.argoproj.io/sync-wave: "5"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: kueue-clusterqueue-viewer
subjects:
  - kind: ServiceAccount
    name: gpu-switchboard
    namespace: private-ai
