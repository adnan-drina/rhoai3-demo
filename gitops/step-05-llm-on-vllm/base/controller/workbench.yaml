# =============================================================================
# GPU Switchboard Workbench - RHOAI 3.0 GA Aligned
# =============================================================================
# Pre-configured workbench for the GPU-as-a-Service demo.
#
# RHOAI 3.0 Alignment:
#   - OAuth: Uses inject-oauth annotation (centralized at Gateway level)
#   - Resources: Delegated to Hardware Profile Controller (cpu-small)
#   - Kueue: Relies on namespace-level kueue.openshift.io/managed label
#   - RBAC: Explicit permissions for InferenceService management
#   - Git-Sync: Uses init container to pull notebooks from Git (not ConfigMap)
#   - Ingress: Native Ingress Controller with port 8888 alignment
#
# Native Ingress Pattern:
#   In RHOAI 3.0, we utilize the Native Ingress Controller. The Service is
#   aligned to port 8888 to match the platform's automated HTTPRoute generation.
#   This eliminates routing conflicts, satisfies Service Mesh port-naming
#   requirements, and ensures the 'Open' button in the RHOAI Dashboard works.
#
# The Hardware Profile Controller will inject CPU/memory resources automatically.
# This demonstrates the "Platform-as-a-Service" philosophy of RHOAI 3.0.
#
# Ref: https://docs.redhat.com/en/documentation/red_hat_openshift_ai_self-managed/3.0/html-single/working_with_accelerators/index#working-with-hardware-profiles
# Ref: https://docs.redhat.com/en/documentation/red_hat_openshift_ai_self-managed/3.0/html-single/working_in_your_data_science_ide/index#creating-a-workbench_ide
# =============================================================================

# -----------------------------------------------------------------------------
# ServiceAccount: Workbench Identity
# -----------------------------------------------------------------------------
apiVersion: v1
kind: ServiceAccount
metadata:
  name: gpu-switchboard
  namespace: private-ai
  labels:
    app: gpu-switchboard
    opendatahub.io/dashboard: "true"
  annotations:
    argocd.argoproj.io/sync-wave: "5"
---
# -----------------------------------------------------------------------------
# PVC: Workbench Storage
# -----------------------------------------------------------------------------
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: gpu-switchboard-storage
  namespace: private-ai
  labels:
    app: gpu-switchboard
    opendatahub.io/dashboard: "true"
  annotations:
    argocd.argoproj.io/sync-wave: "5"
    openshift.io/display-name: gpu-switchboard-storage
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 20Gi
  storageClassName: gp3-csi
---
# -----------------------------------------------------------------------------
# Service: Cooperative GitOps with RHOAI 3.0 Notebook Controller
# -----------------------------------------------------------------------------
# RHOAI 3.0 Managed Ingress Pattern:
#   The Notebook Controller creates HTTPRoutes targeting port 8888, but its
#   default Service uses port 80. This causes "cluster_not_found" errors.
#
#   Solution: Provide a GitOps-managed Service that satisfies all parties:
#   - Port 8888 (matches controller's HTTPRoute)
#   - Label 'notebook-name' (allows controller adoption)
#   - Port name 'http-' prefix (Envoy protocol detection)
#   - Selector 'notebook-name' (matches pod labels)
#
#   Traffic flow: Gateway → HTTPRoute(8888) → Service(8888) → Pod(8888)
#
# This is the "Cooperative GitOps" model - we align with controller expectations
# rather than fighting the reconciliation loop.
#
# Ref: https://docs.redhat.com/en/documentation/red_hat_openshift_ai_self-managed/3.0
# -----------------------------------------------------------------------------
apiVersion: v1
kind: Service
metadata:
  name: gpu-switchboard
  namespace: private-ai
  labels:
    app: gpu-switchboard
    notebook-name: gpu-switchboard
  annotations:
    argocd.argoproj.io/sync-wave: "8"
spec:
  ports:
    - name: http-gpu-switchboard  # Protocol prefix 'http-' required for Envoy
      port: 8888                   # Match controller's HTTPRoute target
      protocol: TCP
      targetPort: 8888             # Pod port
  selector:
    # Use notebook-name for controller adoption (per RHOAI 3.0 guidelines)
    notebook-name: gpu-switchboard
  type: ClusterIP
---
# -----------------------------------------------------------------------------
# Notebook: GPU Switchboard
# -----------------------------------------------------------------------------
# Resources are DELEGATED to the Hardware Profile Controller.
# The controller injects cpu-small specs (cpu: 2/4, memory: 4Gi/8Gi).
#
# Git-Sync Pattern:
#   An init container clones the demo repository into the PVC before Jupyter
#   starts. This is cleaner than storing JSON notebooks in ConfigMaps.
# -----------------------------------------------------------------------------
apiVersion: kubeflow.org/v1
kind: Notebook
metadata:
  name: gpu-switchboard
  namespace: private-ai
  labels:
    app: gpu-switchboard
    opendatahub.io/dashboard: "true"
    opendatahub.io/odh-managed: "true"
  annotations:
    argocd.argoproj.io/sync-wave: "10"
    # RHOAI 3.0: Correct OAuth annotation for sidecar injection
    notebooks.opendatahub.io/inject-oauth: "true"
    # Hardware Profile: Delegates resource management to the platform
    opendatahub.io/hardware-profile-name: cpu-small
    opendatahub.io/hardware-profile-namespace: redhat-ods-applications
    # UI Metadata - Required to avoid "Deprecated" warning
    opendatahub.io/image-display-name: "Jupyter | Data Science | CPU | Python 3.12"
    opendatahub.io/username: ai-admin
    notebooks.opendatahub.io/last-image-selection: s2i-generic-data-science-notebook:2025.2
    notebooks.opendatahub.io/last-image-version-git-commit-selection: d3137ca
    openshift.io/display-name: "GPU Switchboard"
    openshift.io/description: "Interactive notebook for GPU-as-a-Service demo - control 5 models with toggle switches"
spec:
  template:
    spec:
      enableServiceLinks: false
      serviceAccountName: gpu-switchboard
      # =========================================================================
      # Git-Sync Init Container
      # =========================================================================
      # Clones the demo repository into the workspace PVC before Jupyter starts.
      # This is the recommended RHOAI 3.0 pattern for pre-loading notebooks.
      #
      # Benefits over ConfigMap:
      #   - No 1MB size limit
      #   - Version-controlled in Git (single source of truth)
      #   - Users can save changes that persist across restarts
      #   - Clean YAML without embedded JSON
      # =========================================================================
      initContainers:
        - name: git-sync
          image: alpine/git:latest
          command:
            - /bin/sh
            - -c
            - |
              set -e
              REPO_URL="https://github.com/adnan-drina/rhoai3-demo.git"
              WORKSPACE="/opt/app-root/src"
              NOTEBOOKS_SRC="gitops/step-05-llm-on-vllm/base/controller"
              
              echo "╔══════════════════════════════════════════════════════════════╗"
              echo "║  Git-Sync: Loading GPU Orchestrator Notebook                 ║"
              echo "╚══════════════════════════════════════════════════════════════╝"
              
              # Only sync if the notebook doesn't exist (preserves user changes)
              if [ ! -f "$WORKSPACE/GPU-Orchestrator.ipynb" ]; then
                echo "→ Cloning repository..."
                git clone --depth 1 --single-branch "$REPO_URL" /tmp/repo
                
                echo "→ Copying notebooks to workspace..."
                cp /tmp/repo/$NOTEBOOKS_SRC/*.ipynb "$WORKSPACE/" 2>/dev/null || true
                
                echo "→ Copying any additional demo files..."
                cp -r /tmp/repo/$NOTEBOOKS_SRC/data "$WORKSPACE/" 2>/dev/null || true
                
                rm -rf /tmp/repo
                echo "✓ Notebooks synced successfully!"
              else
                echo "✓ Notebooks already exist - skipping sync (preserving user changes)"
              fi
              
              ls -la "$WORKSPACE/"
          volumeMounts:
            - name: gpu-switchboard-storage
              mountPath: /opt/app-root/src
          resources:
            limits:
              cpu: 100m
              memory: 128Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop: ["ALL"]
      containers:
        - name: gpu-switchboard
          image: image-registry.openshift-image-registry.svc:5000/redhat-ods-applications/s2i-generic-data-science-notebook:2025.2
          imagePullPolicy: Always
          workingDir: /opt/app-root/src
          env:
            - name: NOTEBOOK_ARGS
              value: |-
                --ServerApp.port=8888
                --ServerApp.token=''
                --ServerApp.password=''
                --ServerApp.base_url=/notebook/private-ai/gpu-switchboard
                --ServerApp.quit_button=False
            - name: JUPYTER_IMAGE
              value: image-registry.openshift-image-registry.svc:5000/redhat-ods-applications/s2i-generic-data-science-notebook:2025.2
            # SSL/TLS certificates for internal services
            - name: PIP_CERT
              value: /etc/pki/tls/custom-certs/ca-bundle.crt
            - name: REQUESTS_CA_BUNDLE
              value: /etc/pki/tls/custom-certs/ca-bundle.crt
            - name: SSL_CERT_FILE
              value: /etc/pki/tls/custom-certs/ca-bundle.crt
            - name: PIPELINES_SSL_SA_CERTS
              value: /etc/pki/tls/custom-certs/ca-bundle.crt
          ports:
            - containerPort: 8888
              name: notebook-port
              protocol: TCP
          # RHOAI 3.0: Resources DELEGATED to Hardware Profile Controller
          # The cpu-small profile will inject: cpu: 2/4, memory: 4Gi/8Gi
          # This demonstrates the "Platform-as-a-Service" architecture
          resources: {}
          livenessProbe:
            httpGet:
              path: /notebook/private-ai/gpu-switchboard/api
              port: notebook-port
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 5
            timeoutSeconds: 1
            successThreshold: 1
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /notebook/private-ai/gpu-switchboard/api
              port: notebook-port
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 5
            timeoutSeconds: 1
            successThreshold: 1
            failureThreshold: 3
          volumeMounts:
            - name: gpu-switchboard-storage
              mountPath: /opt/app-root/src/
            - name: shm
              mountPath: /dev/shm
            - name: trusted-ca
              mountPath: /etc/pki/tls/custom-certs/ca-bundle.crt
              subPath: ca-bundle.crt
              readOnly: true
            - name: runtime-images
              mountPath: /opt/app-root/pipeline-runtimes/
      volumes:
        - name: gpu-switchboard-storage
          persistentVolumeClaim:
            claimName: gpu-switchboard-storage
        - name: shm
          emptyDir:
            medium: Memory
        - name: trusted-ca
          configMap:
            name: workbench-trusted-ca-bundle
            optional: true
            items:
              - key: ca-bundle.crt
                path: ca-bundle.crt
        - name: runtime-images
          configMap:
            name: pipeline-runtime-images
            optional: true
---
# =============================================================================
# NetworkPolicy: Allow Gateway Ingress
# =============================================================================
# The Notebook Controller creates NetworkPolicies that only allow traffic from
# redhat-ods-applications namespace. However, the Gateway (Envoy) runs in
# openshift-ingress namespace, so we need an additional policy.
#
# Without this, requests timeout with:
#   "upstream connect error... connection timeout"
# =============================================================================
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: gpu-switchboard-gateway-ingress
  namespace: private-ai
  labels:
    app: gpu-switchboard
  annotations:
    argocd.argoproj.io/sync-wave: "8"
spec:
  podSelector:
    matchLabels:
      notebook-name: gpu-switchboard
  policyTypes:
    - Ingress
  ingress:
    - from:
        - namespaceSelector:
            matchLabels:
              kubernetes.io/metadata.name: openshift-ingress
      ports:
        - port: 8888
          protocol: TCP
---
# =============================================================================
# RBAC: GPU Switchboard Controller Permissions
# =============================================================================
# Allows the workbench to manage InferenceServices and view Kueue resources.
#
# Required for the notebook's `oc patch` commands to toggle models ON/OFF.
# =============================================================================

# Role: InferenceService management in private-ai namespace
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: gpu-switchboard-controller
  namespace: private-ai
  labels:
    app: gpu-switchboard
  annotations:
    argocd.argoproj.io/sync-wave: "5"
rules:
  # InferenceService management (get, list, patch, update)
  - apiGroups: ["serving.kserve.io"]
    resources: ["inferenceservices"]
    verbs: ["get", "list", "watch", "patch", "update"]
  # Pod status (for checking if model is running)
  - apiGroups: [""]
    resources: ["pods"]
    verbs: ["get", "list", "watch"]
  # Kueue workloads (for queue status)
  - apiGroups: ["kueue.x-k8s.io"]
    resources: ["workloads", "localqueues"]
    verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: gpu-switchboard-controller
  namespace: private-ai
  labels:
    app: gpu-switchboard
  annotations:
    argocd.argoproj.io/sync-wave: "5"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: gpu-switchboard-controller
subjects:
  - kind: ServiceAccount
    name: gpu-switchboard
    namespace: private-ai
---
# ClusterRole: View ClusterQueues (cluster-scoped resource)
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: kueue-clusterqueue-viewer
  labels:
    app: gpu-switchboard
  annotations:
    argocd.argoproj.io/sync-wave: "5"
rules:
  - apiGroups: ["kueue.x-k8s.io"]
    resources: ["clusterqueues", "resourceflavors"]
    verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: gpu-switchboard-kueue-viewer
  labels:
    app: gpu-switchboard
  annotations:
    argocd.argoproj.io/sync-wave: "5"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: kueue-clusterqueue-viewer
subjects:
  - kind: ServiceAccount
    name: gpu-switchboard
    namespace: private-ai
