# =============================================================================
# GPU Switchboard Workbench - RHOAI 3.0 GA Aligned
# =============================================================================
# Pre-configured workbench for the GPU-as-a-Service demo.
#
# RHOAI 3.0 Alignment:
#   - OAuth: Uses inject-oauth annotation for OAuth proxy sidecar
#   - Resources: Delegated to Hardware Profile Controller (cpu-small)
#   - Kueue: Relies on namespace-level kueue.openshift.io/managed label
#   - RBAC: Explicit permissions for InferenceService management
#
# The Hardware Profile Controller will inject CPU/memory resources automatically.
# This demonstrates the "Platform-as-a-Service" philosophy of RHOAI 3.0.
#
# Ref: https://docs.redhat.com/en/documentation/red_hat_openshift_ai_self-managed/3.0/html-single/working_with_accelerators/index#working-with-hardware-profiles
# Ref: https://docs.redhat.com/en/documentation/red_hat_openshift_ai_self-managed/3.0/html-single/working_in_your_data_science_ide/index#creating-a-workbench_ide
# =============================================================================

# -----------------------------------------------------------------------------
# ServiceAccount: Workbench Identity
# -----------------------------------------------------------------------------
apiVersion: v1
kind: ServiceAccount
metadata:
  name: gpu-switchboard
  namespace: private-ai
  labels:
    app: gpu-switchboard
    opendatahub.io/dashboard: "true"
  annotations:
    argocd.argoproj.io/sync-wave: "5"
---
# -----------------------------------------------------------------------------
# PVC: Workbench Storage
# -----------------------------------------------------------------------------
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: gpu-switchboard-storage
  namespace: private-ai
  labels:
    app: gpu-switchboard
    opendatahub.io/dashboard: "true"
  annotations:
    argocd.argoproj.io/sync-wave: "5"
    openshift.io/display-name: gpu-switchboard-storage
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 20Gi
  storageClassName: gp3-csi
---
# -----------------------------------------------------------------------------
# Notebook: GPU Switchboard
# -----------------------------------------------------------------------------
# Resources are DELEGATED to the Hardware Profile Controller.
# The controller injects cpu-small specs (cpu: 2/4, memory: 4Gi/8Gi).
# -----------------------------------------------------------------------------
apiVersion: kubeflow.org/v1
kind: Notebook
metadata:
  name: gpu-switchboard
  namespace: private-ai
  labels:
    app: gpu-switchboard
    opendatahub.io/dashboard: "true"
    opendatahub.io/odh-managed: "true"
    # NOTE: Removed kueue.x-k8s.io/queue-name - using namespace-level Kueue management
  annotations:
    argocd.argoproj.io/sync-wave: "10"
    # RHOAI 3.0: Correct OAuth annotation for sidecar injection
    notebooks.opendatahub.io/inject-oauth: "true"
    # Hardware Profile: Delegates resource management to the platform
    opendatahub.io/hardware-profile-name: cpu-small
    opendatahub.io/hardware-profile-namespace: redhat-ods-applications
    # UI Metadata
    opendatahub.io/image-display-name: "Jupyter | Data Science | CPU | Python 3.12"
    opendatahub.io/username: ai-admin
    notebooks.opendatahub.io/last-image-selection: s2i-generic-data-science-notebook:2025.2
    openshift.io/display-name: "GPU Switchboard"
    openshift.io/description: "Interactive notebook for GPU-as-a-Service demo - control 5 models with toggle switches"
spec:
  template:
    spec:
      enableServiceLinks: false
      serviceAccountName: gpu-switchboard
      containers:
        - name: gpu-switchboard
          image: image-registry.openshift-image-registry.svc:5000/redhat-ods-applications/s2i-generic-data-science-notebook:2025.2
          imagePullPolicy: Always
          workingDir: /opt/app-root/src
          env:
            - name: NOTEBOOK_ARGS
              value: |-
                --ServerApp.port=8888
                --ServerApp.token=''
                --ServerApp.password=''
                --ServerApp.base_url=/notebook/private-ai/gpu-switchboard
                --ServerApp.quit_button=False
            - name: JUPYTER_IMAGE
              value: image-registry.openshift-image-registry.svc:5000/redhat-ods-applications/s2i-generic-data-science-notebook:2025.2
            # SSL/TLS certificates for internal services
            - name: PIP_CERT
              value: /etc/pki/tls/custom-certs/ca-bundle.crt
            - name: REQUESTS_CA_BUNDLE
              value: /etc/pki/tls/custom-certs/ca-bundle.crt
            - name: SSL_CERT_FILE
              value: /etc/pki/tls/custom-certs/ca-bundle.crt
            - name: PIPELINES_SSL_SA_CERTS
              value: /etc/pki/tls/custom-certs/ca-bundle.crt
          ports:
            - containerPort: 8888
              name: notebook-port
              protocol: TCP
          # RHOAI 3.0: Resources DELEGATED to Hardware Profile Controller
          # The cpu-small profile will inject: cpu: 2/4, memory: 4Gi/8Gi
          # This demonstrates the "Platform-as-a-Service" architecture
          resources: {}
          livenessProbe:
            httpGet:
              path: /notebook/private-ai/gpu-switchboard/api
              port: notebook-port
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 5
            timeoutSeconds: 1
            successThreshold: 1
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /notebook/private-ai/gpu-switchboard/api
              port: notebook-port
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 5
            timeoutSeconds: 1
            successThreshold: 1
            failureThreshold: 3
          volumeMounts:
            - name: gpu-switchboard-storage
              mountPath: /opt/app-root/src/
            - name: shm
              mountPath: /dev/shm
            - name: trusted-ca
              mountPath: /etc/pki/tls/custom-certs/ca-bundle.crt
              subPath: ca-bundle.crt
              readOnly: true
            - name: runtime-images
              mountPath: /opt/app-root/pipeline-runtimes/
            # Pre-loaded notebook from ConfigMap
            - name: gpu-switchboard-notebook
              mountPath: /opt/app-root/src/GPU-Switchboard.ipynb
              subPath: GPU-Switchboard.ipynb
      volumes:
        - name: gpu-switchboard-storage
          persistentVolumeClaim:
            claimName: gpu-switchboard-storage
        - name: shm
          emptyDir:
            medium: Memory
        - name: trusted-ca
          configMap:
            name: workbench-trusted-ca-bundle
            optional: true
            items:
              - key: ca-bundle.crt
                path: ca-bundle.crt
        - name: runtime-images
          configMap:
            name: pipeline-runtime-images
            optional: true
        - name: gpu-switchboard-notebook
          configMap:
            name: gpu-switchboard-notebook
---
# =============================================================================
# RBAC: GPU Switchboard Controller Permissions
# =============================================================================
# Allows the workbench to manage InferenceServices and view Kueue resources.
#
# Required for the notebook's `oc patch` commands to toggle models ON/OFF.
# =============================================================================

# Role: InferenceService management in private-ai namespace
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: gpu-switchboard-controller
  namespace: private-ai
  labels:
    app: gpu-switchboard
  annotations:
    argocd.argoproj.io/sync-wave: "5"
rules:
  # InferenceService management (get, list, patch, update)
  - apiGroups: ["serving.kserve.io"]
    resources: ["inferenceservices"]
    verbs: ["get", "list", "watch", "patch", "update"]
  # Pod status (for checking if model is running)
  - apiGroups: [""]
    resources: ["pods"]
    verbs: ["get", "list", "watch"]
  # Kueue workloads (for queue status)
  - apiGroups: ["kueue.x-k8s.io"]
    resources: ["workloads", "localqueues"]
    verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: gpu-switchboard-controller
  namespace: private-ai
  labels:
    app: gpu-switchboard
  annotations:
    argocd.argoproj.io/sync-wave: "5"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: gpu-switchboard-controller
subjects:
  - kind: ServiceAccount
    name: gpu-switchboard
    namespace: private-ai
---
# ClusterRole: View ClusterQueues (cluster-scoped resource)
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: kueue-clusterqueue-viewer
  labels:
    app: gpu-switchboard
  annotations:
    argocd.argoproj.io/sync-wave: "5"
rules:
  - apiGroups: ["kueue.x-k8s.io"]
    resources: ["clusterqueues", "resourceflavors"]
    verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: gpu-switchboard-kueue-viewer
  labels:
    app: gpu-switchboard
  annotations:
    argocd.argoproj.io/sync-wave: "5"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: kueue-clusterqueue-viewer
subjects:
  - kind: ServiceAccount
    name: gpu-switchboard
    namespace: private-ai
