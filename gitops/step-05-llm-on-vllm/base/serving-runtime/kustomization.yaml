apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

# vLLM ServingRuntime
# Provides the inference engine for LLM serving

resources:
  - vllm-runtime.yaml

