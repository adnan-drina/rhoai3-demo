# =============================================================================
# Model Upload: Mistral Small 24B AWQ (4-bit Quantized)
# =============================================================================
# For 1-GPU deployment on g6.4xlarge (24GB VRAM)
#
# AWQ (Activation-aware Weight Quantization) provides:
#   - 4-bit weights (~13.5GB vs 21.5GB FP8 vs 48GB BF16)
#   - High accuracy (superior to GPTQ)
#   - Native vLLM kernel support
#   - Recommended by Red Hat/Neural Magic for 24GB GPUs
#
# Usage:
#   oc create secret generic hf-token -n minio-storage --from-literal=token=hf_xxx
#   oc apply -f upload-mistral-awq.yaml
#   oc logs -f job/upload-mistral-awq -n minio-storage
# =============================================================================
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mistral-awq-pvc
  namespace: minio-storage
  annotations:
    argocd.argoproj.io/hook: Skip
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 40Gi  # AWQ 4-bit is ~13.5GB
---
apiVersion: batch/v1
kind: Job
metadata:
  name: upload-mistral-awq
  namespace: minio-storage
  annotations:
    argocd.argoproj.io/hook: Skip
spec:
  ttlSecondsAfterFinished: 3600
  backoffLimit: 3
  template:
    spec:
      restartPolicy: OnFailure
      securityContext:
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      volumes:
        - name: model-storage
          persistentVolumeClaim:
            claimName: mistral-awq-pvc
      containers:
        - name: uploader
          image: python:3.11-slim
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop: ["ALL"]
          volumeMounts:
            - name: model-storage
              mountPath: /models
          command:
            - /bin/bash
            - -c
            - |
              set -e
              export HOME=/tmp
              MODEL_NAME="Mistral-Small-24B-AWQ"
              HF_REPO="neuralmagic/Mistral-Small-Instruct-2412-AWQ"
              S3_PREFIX="mistral-small-24b-awq"
              
              echo "╔══════════════════════════════════════════════════════════════╗"
              echo "║  Model Upload: ${MODEL_NAME}                                 ║"
              echo "║  HuggingFace: ${HF_REPO}                                     ║"
              echo "║  Target: s3://models/${S3_PREFIX}/                           ║"
              echo "║                                                              ║"
              echo "║  AWQ Benefits:                                               ║"
              echo "║    • 4-bit weights (~13.5GB vs 21.5GB FP8)                   ║"
              echo "║    • Fits on single L4 24GB with 8k context                  ║"
              echo "║    • Higher accuracy than GPTQ                               ║"
              echo "╚══════════════════════════════════════════════════════════════╝"
              
              pip install --user -q huggingface_hub boto3
              export PATH="$HOME/.local/bin:$PATH"

              python3 << PYTHON_SCRIPT
              import os, sys
              from huggingface_hub import snapshot_download
              import boto3
              from botocore.config import Config
              from pathlib import Path

              BUCKET = "models"
              S3_PREFIX = "${S3_PREFIX}"
              MODEL_DIR = "/models/${S3_PREFIX}"
              HF_REPO = "${HF_REPO}"

              s3 = boto3.client('s3',
                  endpoint_url=os.environ['MINIO_ENDPOINT'],
                  aws_access_key_id=os.environ['MINIO_ACCESS_KEY'],
                  aws_secret_access_key=os.environ['MINIO_SECRET_KEY'],
                  config=Config(signature_version='s3v4'))

              # Check if already in MinIO
              try:
                  resp = s3.list_objects_v2(Bucket=BUCKET, Prefix=f"{S3_PREFIX}/", MaxKeys=5)
                  if resp.get('KeyCount', 0) >= 5:
                      print(f"✓ Model already in MinIO - skipping")
                      sys.exit(0)
              except: pass

              # Download from HuggingFace
              model_path = Path(MODEL_DIR)
              if not model_path.exists() or not any(model_path.glob("*.safetensors")):
                  print(f"Downloading {HF_REPO}...")
                  snapshot_download(repo_id=HF_REPO, local_dir=MODEL_DIR,
                      token=os.environ.get("HF_TOKEN"),
                      ignore_patterns=["*.md", "*.txt", "*.git*"])
              else:
                  print(f"✓ Model found on PVC")

              # Upload to MinIO
              print("Uploading to MinIO...")
              for f in Path(MODEL_DIR).rglob("*"):
                  if f.is_file():
                      key = f"{S3_PREFIX}/{f.relative_to(MODEL_DIR)}"
                      print(f"  → {key}")
                      s3.upload_file(str(f), BUCKET, key)
              print(f"✓ Done: s3://{BUCKET}/{S3_PREFIX}/")
              PYTHON_SCRIPT
          env:
            - name: HF_TOKEN
              valueFrom:
                secretKeyRef:
                  name: hf-token
                  key: token
                  optional: true
            - name: MINIO_ACCESS_KEY
              value: "rhoai-access-key"
            - name: MINIO_SECRET_KEY
              value: "rhoai-secret-key-12345"
            - name: MINIO_ENDPOINT
              value: "http://minio:9000"
          resources:
            requests:
              cpu: "2"
              memory: 4Gi
            limits:
              cpu: "4"
              memory: 8Gi

