# =============================================================================
# Step 05: LLM Model Registration - S3 Registry Handshake
# =============================================================================
# Registers models with S3 URIs in the Model Registry.
# The Registry stores the "Blueprint" (metadata + S3 pointer), not the weights.
#
# RHOAI 3.0 Handshake Pattern:
#   Registry (Metadata) → MinIO (Weights) → KServe (Execution)
#
# When users click "Deploy" in GenAI Studio, RHOAI:
#   1. Reads the 'uri' field from the ModelArtifact
#   2. Auto-fills the storageUri in the InferenceService
#   3. Uses the Data Connection secret for credentials
#
# Ref: https://docs.redhat.com/en/documentation/red_hat_openshift_ai_self-managed/3.0/html-single/working_with_model_registries/index
# =============================================================================
apiVersion: batch/v1
kind: Job
metadata:
  name: llm-model-registration
  namespace: rhoai-model-registries
  labels:
    app: llm-model-registration
  annotations:
    argocd.argoproj.io/sync-wave: "1"
    argocd.argoproj.io/hook: Sync
    argocd.argoproj.io/hook-delete-policy: BeforeHookCreation
spec:
  backoffLimit: 5
  ttlSecondsAfterFinished: 300
  template:
    metadata:
      labels:
        app: llm-model-registration
    spec:
      restartPolicy: OnFailure
      securityContext:
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      containers:
        - name: register
          image: quay.io/curl/curl:latest
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop: ["ALL"]
          env:
            - name: REGISTRY_URL
              value: "http://private-ai-registry-internal.rhoai-model-registries.svc:8080"
            # S3 Configuration for MinIO
            - name: S3_ENDPOINT
              value: "http://minio.minio-storage.svc:9000"
            - name: S3_BUCKET
              value: "models"
          command:
            - /bin/sh
            - -c
            - |
              set -e
              echo "╔══════════════════════════════════════════════════════════════╗"
              echo "║  Step 05: LLM Model Registration (S3 Handshake)              ║"
              echo "║  Registry stores metadata → MinIO stores weights             ║"
              echo "╚══════════════════════════════════════════════════════════════╝"
              
              API_BASE="${REGISTRY_URL}/api/model_registry/v1alpha3"
              
              echo "Waiting for Model Registry API..."
              for i in $(seq 1 30); do
                if curl -sf "${API_BASE}/registered_models" > /dev/null 2>&1; then
                  echo "✓ Model Registry API is ready!"
                  break
                fi
                echo "  Attempt $i/30 - waiting..."
                sleep 10
              done
              
              # ═══════════════════════════════════════════════════════════════════
              # Function to register a model with S3 URI
              # ═══════════════════════════════════════════════════════════════════
              register_model() {
                local MODEL_NAME="$1"
                local MODEL_DESC="$2"
                local MODEL_TAGS="$3"
                local VERSION_NAME="$4"
                local VERSION_META="$5"
                local S3_PATH="$6"
                local SOURCE_NAME="$7"
                local MODEL_FORMAT="$8"
                
                # Construct full S3 URI
                local ARTIFACT_URI="s3://${S3_BUCKET}/${S3_PATH}"
                
                echo ""
                echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
                echo "Registering: ${MODEL_NAME}"
                echo "  S3 URI: ${ARTIFACT_URI}"
                echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
                
                if curl -sf "${API_BASE}/registered_models" | grep -q "\"name\":\"${MODEL_NAME}\""; then
                  echo "✓ Model '${MODEL_NAME}' already exists - skipping"
                  return 0
                fi
                
                # Create RegisteredModel
                MODEL_RESP=$(curl -sf -X POST "${API_BASE}/registered_models" \
                  -H "Content-Type: application/json" \
                  -d "{
                    \"name\": \"${MODEL_NAME}\",
                    \"description\": \"${MODEL_DESC}\",
                    \"owner\": \"ai-admin\",
                    \"customProperties\": ${MODEL_TAGS}
                  }")
                MODEL_ID=$(echo "$MODEL_RESP" | sed 's/.*"id":"\([^"]*\)".*/\1/' | head -1)
                echo "  Created RegisteredModel ID: ${MODEL_ID}"
                
                # Create ModelVersion
                VERSION_RESP=$(curl -sf -X POST "${API_BASE}/model_versions" \
                  -H "Content-Type: application/json" \
                  -d "{
                    \"name\": \"${VERSION_NAME}\",
                    \"description\": \"Production-ready version for RHOAI 3.0\",
                    \"author\": \"ai-admin\",
                    \"registeredModelId\": \"${MODEL_ID}\",
                    \"customProperties\": ${VERSION_META}
                  }")
                VERSION_ID=$(echo "$VERSION_RESP" | sed 's/.*"id":"\([^"]*\)".*/\1/' | head -1)
                echo "  Created ModelVersion ID: ${VERSION_ID}"
                
                # Create ModelArtifact with S3 metadata (Official RHOAI 3.0 format)
                # This enables the "Deploy from Registry" flow in GenAI Studio
                curl -sf -X POST "${API_BASE}/model_versions/${VERSION_ID}/artifacts" \
                  -H "Content-Type: application/json" \
                  -d "{
                    \"name\": \"${VERSION_NAME}\",
                    \"uri\": \"${ARTIFACT_URI}\",
                    \"artifactType\": \"model-artifact\",
                    \"modelFormatName\": \"${MODEL_FORMAT}\",
                    \"customProperties\": {
                      \"s3_endpoint\": {\"metadataType\": \"MetadataStringValue\", \"string_value\": \"${S3_ENDPOINT}\"},
                      \"s3_bucket\": {\"metadataType\": \"MetadataStringValue\", \"string_value\": \"${S3_BUCKET}\"},
                      \"format\": {\"metadataType\": \"MetadataStringValue\", \"string_value\": \"safetensors\"},
                      \"source_model\": {\"metadataType\": \"MetadataStringValue\", \"string_value\": \"${SOURCE_NAME}\"}
                    }
                  }" > /dev/null
                
                echo "✓ Registered: ${MODEL_NAME} → ${ARTIFACT_URI}"
              }
              
              # ═══════════════════════════════════════════════════════════════════
              # Model 1: Mistral Small 24B BF16 (4-GPU, Full Precision)
              # ═══════════════════════════════════════════════════════════════════
              register_model \
                "Mistral-Small-24B-Instruct-BF16" \
                "Mistral Small 24B Instruct - Full Precision BF16 for 4-GPU tensor parallel deployment. Requires g6.12xlarge (96GB VRAM)." \
                '{"mistral":{"metadataType":"MetadataStringValue","string_value":""},"validated":{"metadataType":"MetadataStringValue","string_value":""},"vllm":{"metadataType":"MetadataStringValue","string_value":""},"text-to-text":{"metadataType":"MetadataStringValue","string_value":""}}' \
                "v1.0-BF16" \
                '{"License":{"metadataType":"MetadataStringValue","string_value":"Apache-2.0"},"Provider":{"metadataType":"MetadataStringValue","string_value":"Mistral AI"},"precision":{"metadataType":"MetadataStringValue","string_value":"bfloat16"},"gpu_requirement":{"metadataType":"MetadataStringValue","string_value":"4x NVIDIA L4 (g6.12xlarge)"},"tensor_parallel":{"metadataType":"MetadataStringValue","string_value":"4"},"validated_on":{"metadataType":"MetadataStringValue","string_value":"RHOAI 3.0 GA"}}' \
                "mistral-small-24b/" \
                "mistralai/Mistral-Small-24B-Instruct-2501" \
                "vLLM"
              
              # ═══════════════════════════════════════════════════════════════════
              # Model 2: Mistral Small 24B FP8 (1-GPU, Neural Magic Optimized)
              # ═══════════════════════════════════════════════════════════════════
              register_model \
                "Mistral-Small-24B-Instruct-FP8" \
                "Mistral Small 24B Instruct - FP8 Quantized by Neural Magic for cost-efficient 1-GPU deployment. 75% cost savings vs BF16." \
                '{"mistral":{"metadataType":"MetadataStringValue","string_value":""},"fp8":{"metadataType":"MetadataStringValue","string_value":""},"validated":{"metadataType":"MetadataStringValue","string_value":""},"vllm":{"metadataType":"MetadataStringValue","string_value":""},"neural-magic":{"metadataType":"MetadataStringValue","string_value":""}}' \
                "v1.0-FP8" \
                '{"License":{"metadataType":"MetadataStringValue","string_value":"Apache-2.0"},"Provider":{"metadataType":"MetadataStringValue","string_value":"Neural Magic"},"quantization":{"metadataType":"MetadataStringValue","string_value":"fp8"},"optimized_for":{"metadataType":"MetadataStringValue","string_value":"nvidia-l4"},"gpu_requirement":{"metadataType":"MetadataStringValue","string_value":"1x NVIDIA L4 (g6.4xlarge)"},"vram_usage":{"metadataType":"MetadataStringValue","string_value":"~15GB"},"cost_savings":{"metadataType":"MetadataStringValue","string_value":"75% vs BF16"},"validated_on":{"metadataType":"MetadataStringValue","string_value":"RHOAI 3.0 GA"}}' \
                "mistral-small-24b-fp8/" \
                "neuralmagic/Mistral-Small-24B-Instruct-2501-FP8-dynamic" \
                "vLLM"
              
              echo ""
              echo "════════════════════════════════════════════════════════════════"
              echo "✓ Model Registration Complete"
              echo ""
              echo "  RHOAI 3.0 S3 Handshake Pattern:"
              echo "  ┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐"
              echo "  │  Model Registry │ →  │      MinIO      │ →  │     KServe      │"
              echo "  │   (Metadata)    │    │    (Weights)    │    │   (Execution)   │"
              echo "  └─────────────────┘    └─────────────────┘    └─────────────────┘"
              echo ""
              echo "  Models registered with S3 URIs:"
              echo "    1. Mistral-Small-24B-Instruct-BF16 → s3://models/mistral-small-24b/"
              echo "    2. Mistral-Small-24B-Instruct-FP8  → s3://models/mistral-small-24b-fp8/"
              echo ""
              echo "  Next: Upload weights to MinIO, then deploy from GenAI Studio"
              echo "════════════════════════════════════════════════════════════════"
