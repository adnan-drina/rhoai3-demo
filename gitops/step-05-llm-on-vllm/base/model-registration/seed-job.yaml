# =============================================================================
# Step 05: LLM Model Registration - GPU-as-a-Service Demo
# =============================================================================
# Registers the three models for the "Dynamic Resource Handover" demo.
#
# Models:
#   1. Mistral-3-BF16    â†’ 4-GPU, S3 storage (primary load)
#   2. Mistral-3-INT4    â†’ 1-GPU, OCI ModelCar (secondary load)
#   3. Devstral-2        â†’ 4-GPU, S3 storage (queued asset)
#
# Demo Flow:
#   - Start: BF16 (4) + INT4 (1) = 5/5 GPUs (100% saturated)
#   - Action: Enable Devstral-2 â†’ PENDING in Kueue queue
#   - Resolution: Disable BF16 â†’ Devstral-2 INSTANTLY starts
#
# Ref: https://docs.redhat.com/en/documentation/red_hat_openshift_ai_self-managed/3.0/html-single/working_with_model_registries/index
# =============================================================================
apiVersion: batch/v1
kind: Job
metadata:
  name: llm-model-registration
  namespace: rhoai-model-registries
  labels:
    app: llm-model-registration
  annotations:
    argocd.argoproj.io/sync-wave: "1"
    argocd.argoproj.io/hook: Sync
    argocd.argoproj.io/hook-delete-policy: BeforeHookCreation
spec:
  backoffLimit: 5
  ttlSecondsAfterFinished: 300
  template:
    metadata:
      labels:
        app: llm-model-registration
    spec:
      restartPolicy: OnFailure
      securityContext:
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      containers:
        - name: register
          image: quay.io/curl/curl:latest
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop: ["ALL"]
          env:
            - name: REGISTRY_URL
              value: "http://private-ai-registry-internal.rhoai-model-registries.svc:8080"
            # S3 Configuration for MinIO
            - name: S3_ENDPOINT
              value: "http://minio.minio-storage.svc:9000"
            - name: S3_BUCKET
              value: "models"
          command:
            - /bin/sh
            - -c
            - |
              set -e
              echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
              echo "â•‘  Step 05: LLM Model Registration (S3 Handshake)              â•‘"
              echo "â•‘  Registry stores metadata â†’ MinIO stores weights             â•‘"
              echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
              
              API_BASE="${REGISTRY_URL}/api/model_registry/v1alpha3"
              
              echo "Waiting for Model Registry API..."
              for i in $(seq 1 30); do
                if curl -sf "${API_BASE}/registered_models" > /dev/null 2>&1; then
                  echo "âœ“ Model Registry API is ready!"
                  break
                fi
                echo "  Attempt $i/30 - waiting..."
                sleep 10
              done
              
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              # Function to register a model with S3 URI
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              register_model() {
                local MODEL_NAME="$1"
                local MODEL_DESC="$2"
                local MODEL_TAGS="$3"
                local VERSION_NAME="$4"
                local VERSION_META="$5"
                local S3_PATH="$6"
                local SOURCE_NAME="$7"
                local MODEL_FORMAT="$8"
                
                # Construct full S3 URI
                local ARTIFACT_URI="s3://${S3_BUCKET}/${S3_PATH}"
                
                echo ""
                echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
                echo "Registering: ${MODEL_NAME}"
                echo "  S3 URI: ${ARTIFACT_URI}"
                echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
                
                if curl -sf "${API_BASE}/registered_models" | grep -q "\"name\":\"${MODEL_NAME}\""; then
                  echo "âœ“ Model '${MODEL_NAME}' already exists - skipping"
                  return 0
                fi
                
                # Create RegisteredModel
                MODEL_RESP=$(curl -sf -X POST "${API_BASE}/registered_models" \
                  -H "Content-Type: application/json" \
                  -d "{
                    \"name\": \"${MODEL_NAME}\",
                    \"description\": \"${MODEL_DESC}\",
                    \"owner\": \"ai-admin\",
                    \"customProperties\": ${MODEL_TAGS}
                  }")
                MODEL_ID=$(echo "$MODEL_RESP" | sed 's/.*"id":"\([^"]*\)".*/\1/' | head -1)
                echo "  Created RegisteredModel ID: ${MODEL_ID}"
                
                # Create ModelVersion
                VERSION_RESP=$(curl -sf -X POST "${API_BASE}/model_versions" \
                  -H "Content-Type: application/json" \
                  -d "{
                    \"name\": \"${VERSION_NAME}\",
                    \"description\": \"Production-ready version for RHOAI 3.0\",
                    \"author\": \"ai-admin\",
                    \"registeredModelId\": \"${MODEL_ID}\",
                    \"customProperties\": ${VERSION_META}
                  }")
                VERSION_ID=$(echo "$VERSION_RESP" | sed 's/.*"id":"\([^"]*\)".*/\1/' | head -1)
                echo "  Created ModelVersion ID: ${VERSION_ID}"
                
                # Create ModelArtifact with S3 metadata (Official RHOAI 3.0 format)
                # This enables the "Deploy from Registry" flow in GenAI Studio
                curl -sf -X POST "${API_BASE}/model_versions/${VERSION_ID}/artifacts" \
                  -H "Content-Type: application/json" \
                  -d "{
                    \"name\": \"${VERSION_NAME}\",
                    \"uri\": \"${ARTIFACT_URI}\",
                    \"artifactType\": \"model-artifact\",
                    \"modelFormatName\": \"${MODEL_FORMAT}\",
                    \"customProperties\": {
                      \"s3_endpoint\": {\"metadataType\": \"MetadataStringValue\", \"string_value\": \"${S3_ENDPOINT}\"},
                      \"s3_bucket\": {\"metadataType\": \"MetadataStringValue\", \"string_value\": \"${S3_BUCKET}\"},
                      \"format\": {\"metadataType\": \"MetadataStringValue\", \"string_value\": \"safetensors\"},
                      \"source_model\": {\"metadataType\": \"MetadataStringValue\", \"string_value\": \"${SOURCE_NAME}\"}
                    }
                  }" > /dev/null
                
                echo "âœ“ Registered: ${MODEL_NAME} â†’ ${ARTIFACT_URI}"
              }
              
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              # Model 1: Mistral-3-BF16 (4-GPU, Primary Load)
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              register_model \
                "Mistral-3-BF16" \
                "Mistral Small 24B Instruct - BF16 Full Precision. Primary 4-GPU model for high-throughput production." \
                '{"mistral":{"metadataType":"MetadataStringValue","string_value":""},"bf16":{"metadataType":"MetadataStringValue","string_value":""},"validated":{"metadataType":"MetadataStringValue","string_value":""},"vllm":{"metadataType":"MetadataStringValue","string_value":""},"production":{"metadataType":"MetadataStringValue","string_value":""}}' \
                "v1.0-BF16" \
                '{"License":{"metadataType":"MetadataStringValue","string_value":"Apache-2.0"},"Provider":{"metadataType":"MetadataStringValue","string_value":"Mistral AI"},"precision":{"metadataType":"MetadataStringValue","string_value":"bfloat16"},"gpu_requirement":{"metadataType":"MetadataStringValue","string_value":"4x NVIDIA L4 (g6.12xlarge)"},"tensor_parallel":{"metadataType":"MetadataStringValue","string_value":"4"},"context_length":{"metadataType":"MetadataStringValue","string_value":"32768"},"demo_role":{"metadataType":"MetadataStringValue","string_value":"Primary Load"}}' \
                "mistral-small-24b/" \
                "mistralai/Mistral-Small-24B-Instruct-2501" \
                "vLLM"
              
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              # Model 2: Mistral-3-INT4 (1-GPU, Secondary Load)
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              register_model \
                "Mistral-3-INT4" \
                "Mistral Small 24B Instruct - INT4 W4A16 quantized by Neural Magic. Cost-efficient 1-GPU deployment." \
                '{"mistral":{"metadataType":"MetadataStringValue","string_value":""},"int4":{"metadataType":"MetadataStringValue","string_value":""},"w4a16":{"metadataType":"MetadataStringValue","string_value":""},"neural-magic":{"metadataType":"MetadataStringValue","string_value":""},"modelcar":{"metadataType":"MetadataStringValue","string_value":""}}' \
                "v1.5-INT4-W4A16" \
                '{"License":{"metadataType":"MetadataStringValue","string_value":"Apache-2.0"},"Provider":{"metadataType":"MetadataStringValue","string_value":"Neural Magic / Red Hat"},"quantization":{"metadataType":"MetadataStringValue","string_value":"int4-w4a16"},"bits":{"metadataType":"MetadataStringValue","string_value":"4"},"accuracy_recovery":{"metadataType":"MetadataStringValue","string_value":"98.9%"},"gpu_requirement":{"metadataType":"MetadataStringValue","string_value":"1x NVIDIA L4 (g6.4xlarge)"},"demo_role":{"metadataType":"MetadataStringValue","string_value":"Secondary Load"}}' \
                "oci://registry.redhat.io/rhelai1/modelcar-mistral-small-24b-instruct-2501-quantized-w4a16:1.5" \
                "neuralmagic/Mistral-Small-24B-Instruct-2501-quantized.w4a16" \
                "vLLM"
              
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              # Model 3: Devstral-2 (4-GPU, Queued Asset)
              # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              register_model \
                "Devstral-2" \
                "Devstral 2 24B - Agentic model optimized for tool use and function calling. The 'waiting' model in the Resource Handover demo." \
                '{"mistral":{"metadataType":"MetadataStringValue","string_value":""},"devstral":{"metadataType":"MetadataStringValue","string_value":""},"agentic":{"metadataType":"MetadataStringValue","string_value":""},"tool-use":{"metadataType":"MetadataStringValue","string_value":""},"vllm":{"metadataType":"MetadataStringValue","string_value":""}}' \
                "v1.0-Agentic" \
                '{"License":{"metadataType":"MetadataStringValue","string_value":"Apache-2.0"},"Provider":{"metadataType":"MetadataStringValue","string_value":"Mistral AI"},"precision":{"metadataType":"MetadataStringValue","string_value":"bfloat16"},"gpu_requirement":{"metadataType":"MetadataStringValue","string_value":"4x NVIDIA L4 (g6.12xlarge)"},"tensor_parallel":{"metadataType":"MetadataStringValue","string_value":"4"},"features":{"metadataType":"MetadataStringValue","string_value":"tool-calling,agentic"},"demo_role":{"metadataType":"MetadataStringValue","string_value":"Queued Asset"}}' \
                "mistral-small-24b/" \
                "mistralai/Mistral-Small-24B-Instruct-2501" \
                "vLLM"
              
              echo ""
              echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
              echo "âœ“ GPU-as-a-Service Demo Models Registered"
              echo ""
              echo "  ğŸ“Š Baseline State (100% Saturation):"
              echo "  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"
              echo "  â”‚  mistral-3-bf16  â”‚ 4 GPUs â”‚ ON  â”‚ Primary Load              â”‚"
              echo "  â”‚  mistral-3-int4  â”‚ 1 GPU  â”‚ ON  â”‚ Secondary Load            â”‚"
              echo "  â”‚  devstral-2      â”‚ 4 GPUs â”‚ OFF â”‚ Queued Asset              â”‚"
              echo "  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤"
              echo "  â”‚  Total: 5/5 GPUs used (100%)                                â”‚"
              echo "  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
              echo ""
              echo "  ğŸ¬ Demo Flow:"
              echo "    1. Enable Devstral-2 â†’ PENDING (over quota)"
              echo "    2. Disable mistral-3-bf16 â†’ Devstral-2 STARTS instantly"
              echo ""
              echo "  Use the GPU-Switchboard.ipynb notebook to run the demo!"
              echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
