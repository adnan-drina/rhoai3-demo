apiVersion: batch/v1
kind: Job
metadata:
  name: llm-model-registration
  namespace: rhoai-model-registries
  labels:
    app: llm-model-registration
  annotations:
    argocd.argoproj.io/sync-wave: "1"
    argocd.argoproj.io/hook: Sync
    argocd.argoproj.io/hook-delete-policy: BeforeHookCreation
    description: |
      Registers three LLM variants in the Model Registry:
      - Mistral 3 BF16 (4-GPU, tensor parallel)
      - Mistral 3 FP8 (1-GPU, Neural Magic optimized)
      - Devstral 2 BF16 (4-GPU, coding model)
spec:
  backoffLimit: 5
  ttlSecondsAfterFinished: 300
  template:
    metadata:
      labels:
        app: llm-model-registration
    spec:
      restartPolicy: OnFailure
      securityContext:
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      containers:
        - name: register
          image: quay.io/curl/curl:latest
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop: ["ALL"]
          env:
            - name: REGISTRY_URL
              value: "http://private-ai-registry-internal.rhoai-model-registries.svc:8080"
          command:
            - /bin/sh
            - -c
            - |
              set -e
              echo "╔══════════════════════════════════════════════════════════════╗"
              echo "║  Step 05: LLM Model Registration - Triple Play               ║"
              echo "║  Mistral 3 (BF16 + FP8) + Devstral 2 (Coding)                ║"
              echo "╚══════════════════════════════════════════════════════════════╝"
              
              API_BASE="${REGISTRY_URL}/api/model_registry/v1alpha3"
              
              echo "Waiting for Model Registry API..."
              for i in $(seq 1 30); do
                if curl -sf "${API_BASE}/registered_models" > /dev/null 2>&1; then
                  echo "✓ Model Registry API is ready!"
                  break
                fi
                echo "  Attempt $i/30 - waiting..."
                sleep 10
              done
              
              # ═══════════════════════════════════════════════════════════════════
              # Function to register a model
              # ═══════════════════════════════════════════════════════════════════
              register_model() {
                local MODEL_NAME="$1"
                local MODEL_DESC="$2"
                local MODEL_TAGS="$3"
                local VERSION_NAME="$4"
                local VERSION_META="$5"
                local ARTIFACT_URI="$6"
                local SOURCE_NAME="$7"
                
                echo ""
                echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
                echo "Registering: ${MODEL_NAME}"
                echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
                
                if curl -sf "${API_BASE}/registered_models" | grep -q "\"name\":\"${MODEL_NAME}\""; then
                  echo "✓ Model '${MODEL_NAME}' already exists - skipping"
                  return 0
                fi
                
                # Create RegisteredModel
                MODEL_RESP=$(curl -sf -X POST "${API_BASE}/registered_models" \
                  -H "Content-Type: application/json" \
                  -d "{
                    \"name\": \"${MODEL_NAME}\",
                    \"description\": \"${MODEL_DESC}\",
                    \"owner\": \"ai-admin\",
                    \"customProperties\": ${MODEL_TAGS}
                  }")
                MODEL_ID=$(echo "$MODEL_RESP" | sed 's/.*"id":"\([^"]*\)".*/\1/' | head -1)
                echo "  Created RegisteredModel ID: ${MODEL_ID}"
                
                # Create ModelVersion
                VERSION_RESP=$(curl -sf -X POST "${API_BASE}/model_versions" \
                  -H "Content-Type: application/json" \
                  -d "{
                    \"name\": \"${VERSION_NAME}\",
                    \"description\": \"Production-ready version for RHOAI 3.0\",
                    \"author\": \"ai-admin\",
                    \"registeredModelId\": \"${MODEL_ID}\",
                    \"customProperties\": ${VERSION_META}
                  }")
                VERSION_ID=$(echo "$VERSION_RESP" | sed 's/.*"id":"\([^"]*\)".*/\1/' | head -1)
                echo "  Created ModelVersion ID: ${VERSION_ID}"
                
                # Create ModelArtifact
                curl -sf -X POST "${API_BASE}/model_versions/${VERSION_ID}/artifacts" \
                  -H "Content-Type: application/json" \
                  -d "{
                    \"name\": \"${VERSION_NAME}\",
                    \"uri\": \"${ARTIFACT_URI}\",
                    \"artifactType\": \"model-artifact\",
                    \"modelSourceClass\": \"redhat_ai_validated_models\",
                    \"modelSourceKind\": \"catalog\",
                    \"modelSourceName\": \"${SOURCE_NAME}\"
                  }" > /dev/null
                
                echo "✓ Registered: ${MODEL_NAME}"
              }
              
              # ═══════════════════════════════════════════════════════════════════
              # Model 1: Mistral 3 BF16 (4-GPU, Full Precision)
              # ═══════════════════════════════════════════════════════════════════
              register_model \
                "Mistral-3-24B-Instruct-BF16" \
                "Mistral Small 3 24B Instruct - Full Precision BF16 for 4-GPU tensor parallel deployment" \
                '{"mistral":{"metadataType":"MetadataStringValue","string_value":""},"validated":{"metadataType":"MetadataStringValue","string_value":""},"vllm":{"metadataType":"MetadataStringValue","string_value":""},"text-to-text":{"metadataType":"MetadataStringValue","string_value":""}}' \
                "v3-BF16-Validated" \
                '{"License":{"metadataType":"MetadataStringValue","string_value":"https://mistral.ai/licenses/"},"Provider":{"metadataType":"MetadataStringValue","string_value":"Mistral AI"},"precision":{"metadataType":"MetadataStringValue","string_value":"bfloat16"},"gpu_requirement":{"metadataType":"MetadataStringValue","string_value":"4x NVIDIA L4"},"validated_on":{"metadataType":"MetadataStringValue","string_value":"RHOAI 3.0"}}' \
                "s3://models/mistral-3-24b-instruct/" \
                "mistralai/Mistral-Small-3.1-24B-Instruct-2503"
              
              # ═══════════════════════════════════════════════════════════════════
              # Model 2: Mistral 3 FP8 (1-GPU, Neural Magic Optimized)
              # ═══════════════════════════════════════════════════════════════════
              register_model \
                "Mistral-3-24B-Instruct-FP8" \
                "Mistral Small 3 24B Instruct - FP8 Quantized by Neural Magic for 1-GPU deployment" \
                '{"mistral":{"metadataType":"MetadataStringValue","string_value":""},"fp8":{"metadataType":"MetadataStringValue","string_value":""},"validated":{"metadataType":"MetadataStringValue","string_value":""},"vllm":{"metadataType":"MetadataStringValue","string_value":""},"neural-magic":{"metadataType":"MetadataStringValue","string_value":""}}' \
                "v3-FP8-NeuralMagic" \
                '{"License":{"metadataType":"MetadataStringValue","string_value":"https://mistral.ai/licenses/"},"Provider":{"metadataType":"MetadataStringValue","string_value":"Neural Magic"},"quantization":{"metadataType":"MetadataStringValue","string_value":"fp8"},"optimized_for":{"metadataType":"MetadataStringValue","string_value":"nvidia-l4"},"gpu_requirement":{"metadataType":"MetadataStringValue","string_value":"1x NVIDIA L4"},"vram_usage":{"metadataType":"MetadataStringValue","string_value":"~15GB"},"validated_on":{"metadataType":"MetadataStringValue","string_value":"RHOAI 3.0"}}' \
                "s3://models/mistral-3-24b-instruct-fp8/" \
                "neuralmagic/Mistral-Small-3.1-24B-Instruct-2503-FP8-dynamic"
              
              # ═══════════════════════════════════════════════════════════════════
              # Model 3: Devstral 2 BF16 (4-GPU, Coding Model)
              # ═══════════════════════════════════════════════════════════════════
              register_model \
                "Devstral-2-24B-BF16" \
                "Devstral 2 24B - Code-optimized LLM for software development tasks" \
                '{"mistral":{"metadataType":"MetadataStringValue","string_value":""},"validated":{"metadataType":"MetadataStringValue","string_value":""},"vllm":{"metadataType":"MetadataStringValue","string_value":""},"coding":{"metadataType":"MetadataStringValue","string_value":""},"text-to-text":{"metadataType":"MetadataStringValue","string_value":""}}' \
                "v2-BF16-Coding" \
                '{"License":{"metadataType":"MetadataStringValue","string_value":"https://mistral.ai/licenses/"},"Provider":{"metadataType":"MetadataStringValue","string_value":"Mistral AI"},"precision":{"metadataType":"MetadataStringValue","string_value":"bfloat16"},"task":{"metadataType":"MetadataStringValue","string_value":"coding"},"gpu_requirement":{"metadataType":"MetadataStringValue","string_value":"4x NVIDIA L4"},"max_context":{"metadataType":"MetadataStringValue","string_value":"32768"},"validated_on":{"metadataType":"MetadataStringValue","string_value":"RHOAI 3.0"}}' \
                "s3://models/devstral-2-24b/" \
                "mistralai/Devstral-Small-2503"
              
              echo ""
              echo "════════════════════════════════════════════════════════════════"
              echo "✓ Model Registration Complete - Triple Play"
              echo ""
              echo "  Models registered:"
              echo "  1. Mistral-3-24B-Instruct-BF16  (4-GPU, tensor parallel)"
              echo "  2. Mistral-3-24B-Instruct-FP8   (1-GPU, Neural Magic)"
              echo "  3. Devstral-2-24B-BF16          (4-GPU, coding)"
              echo ""
              echo "  Ready for deployment in GenAI Studio → AI Available Assets"
              echo "════════════════════════════════════════════════════════════════"
