# vLLM-Playground: Benchmark Testing UI
# ============================================================================
# Simplified deployment for benchmark testing and result analysis only.
# Based on: https://github.com/micytao/vllm-playground
# Architecture: Option 3 - Kubernetes Job Pattern (for benchmarks)
#
# ⚠️ COMMUNITY TOOLING DISCLAIMER:
# This is a community-driven tool and is NOT an officially supported
# component of Red Hat OpenShift AI 3.0 or the vLLM project.
#
# Purpose:
#   - Run GuideLLM benchmarks against existing InferenceServices
#   - Visualize and analyze benchmark results
#   - NOT for model experimentation (use RHOAI GenAI Playground for that)
#
# Our existing models (benchmarked via GuideLLM):
#   - mistral-3-int4:  http://mistral-3-int4-predictor.private-ai.svc:80/v1
#   - mistral-3-bf16:  http://mistral-3-bf16-predictor.private-ai.svc:80/v1
#   - devstral-2:      http://devstral-2-predictor.private-ai.svc:80/v1
#   - granite-8b-agent: http://granite-8b-agent-predictor.private-ai.svc:80/v1
#   - gpt-oss-20b:     http://gpt-oss-20b-predictor.private-ai.svc:80/v1
#
# Ref: https://github.com/micytao/vllm-playground/blob/main/openshift/README.md
# ============================================================================

# --- ServiceAccount ---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: vllm-playground-sa
  namespace: private-ai
  labels:
    app: vllm-playground
    app.kubernetes.io/part-of: step-07-model-performance-metrics
  annotations:
    argocd.argoproj.io/sync-wave: "10"
---
# --- Role for Job management (benchmarks run as Jobs) ---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: vllm-benchmark-manager
  namespace: private-ai
  labels:
    app: vllm-playground
    app.kubernetes.io/part-of: step-07-model-performance-metrics
  annotations:
    argocd.argoproj.io/sync-wave: "10"
rules:
  # Job management for GuideLLM benchmarks
  - apiGroups: ["batch"]
    resources: ["jobs"]
    verbs: ["get", "list", "watch", "create", "delete"]
  # Pod access for viewing logs
  - apiGroups: [""]
    resources: ["pods", "pods/log"]
    verbs: ["get", "list", "watch"]
  # Service access for discovering InferenceServices
  - apiGroups: [""]
    resources: ["services"]
    verbs: ["get", "list"]
  # PVC access for benchmark results
  - apiGroups: [""]
    resources: ["persistentvolumeclaims"]
    verbs: ["get", "list", "watch"]
---
# --- RoleBinding ---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: vllm-benchmark-manager-binding
  namespace: private-ai
  labels:
    app: vllm-playground
    app.kubernetes.io/part-of: step-07-model-performance-metrics
  annotations:
    argocd.argoproj.io/sync-wave: "10"
subjects:
  - kind: ServiceAccount
    name: vllm-playground-sa
    namespace: private-ai
roleRef:
  kind: Role
  name: vllm-benchmark-manager
  apiGroup: rbac.authorization.k8s.io
---
# --- ClusterRole for node reading (GPU detection for UI) ---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: vllm-playground-node-reader
  labels:
    app: vllm-playground
    app.kubernetes.io/part-of: step-07-model-performance-metrics
  annotations:
    argocd.argoproj.io/sync-wave: "10"
rules:
  - apiGroups: [""]
    resources: ["nodes"]
    verbs: ["get", "list"]
---
# --- ClusterRoleBinding for node reading ---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: vllm-playground-node-reader-binding
  labels:
    app: vllm-playground
    app.kubernetes.io/part-of: step-07-model-performance-metrics
  annotations:
    argocd.argoproj.io/sync-wave: "10"
subjects:
  - kind: ServiceAccount
    name: vllm-playground-sa
    namespace: private-ai
roleRef:
  kind: ClusterRole
  name: vllm-playground-node-reader
  apiGroup: rbac.authorization.k8s.io
---
# --- ConfigMap with existing model endpoints ---
apiVersion: v1
kind: ConfigMap
metadata:
  name: vllm-playground-config
  namespace: private-ai
  labels:
    app: vllm-playground
    app.kubernetes.io/part-of: step-07-model-performance-metrics
  annotations:
    argocd.argoproj.io/sync-wave: "11"
data:
  # Kubernetes namespace
  KUBERNETES_NAMESPACE: "private-ai"
  
  # For benchmarking existing models (no new vLLM pods needed)
  # The playground will benchmark these endpoints with GuideLLM
  VLLM_IMAGE: "vllm/vllm-openai:v0.11.0"
  
  # Web UI port
  WEBUI_PORT: "7860"
  
  # Benchmark results storage
  USE_PERSISTENT_CACHE: "true"
  MODEL_CACHE_PVC: "guidellm-results"
  
  # Pre-configured model endpoints for benchmarking
  # These are our existing InferenceServices
  MODEL_ENDPOINTS: |
    mistral-3-int4=http://mistral-3-int4-predictor.private-ai.svc.cluster.local:80/v1
    mistral-3-bf16=http://mistral-3-bf16-predictor.private-ai.svc.cluster.local:80/v1
    devstral-2=http://devstral-2-predictor.private-ai.svc.cluster.local:80/v1
    granite-8b-agent=http://granite-8b-agent-predictor.private-ai.svc.cluster.local:80/v1
    gpt-oss-20b=http://gpt-oss-20b-predictor.private-ai.svc.cluster.local:80/v1
---
# --- Deployment ---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm-playground
  namespace: private-ai
  labels:
    app: vllm-playground
    app.kubernetes.io/part-of: step-07-model-performance-metrics
  annotations:
    argocd.argoproj.io/sync-wave: "12"
    description: "vLLM Playground - Benchmark testing and analysis UI"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: vllm-playground
  template:
    metadata:
      labels:
        app: vllm-playground
        app.kubernetes.io/part-of: step-07-model-performance-metrics
    spec:
      serviceAccountName: vllm-playground-sa
      containers:
        - name: webui
          # Official vLLM-Playground image (publicly accessible)
          image: quay.io/rh_ee_micyang/vllm-playground:0.3
          imagePullPolicy: Always
          ports:
            - containerPort: 7860
              name: http
              protocol: TCP
          env:
            - name: KUBERNETES_NAMESPACE
              valueFrom:
                configMapKeyRef:
                  name: vllm-playground-config
                  key: KUBERNETES_NAMESPACE
            - name: VLLM_IMAGE
              valueFrom:
                configMapKeyRef:
                  name: vllm-playground-config
                  key: VLLM_IMAGE
            - name: USE_PERSISTENT_CACHE
              valueFrom:
                configMapKeyRef:
                  name: vllm-playground-config
                  key: USE_PERSISTENT_CACHE
            - name: MODEL_CACHE_PVC
              valueFrom:
                configMapKeyRef:
                  name: vllm-playground-config
                  key: MODEL_CACHE_PVC
            - name: WEBUI_PORT
              value: "7860"
          resources:
            requests:
              cpu: 500m
              memory: 1Gi
            limits:
              cpu: "2"
              memory: 4Gi
          volumeMounts:
            # Mount benchmark results PVC
            - name: benchmark-results
              mountPath: /app/results
              readOnly: true
          livenessProbe:
            httpGet:
              path: /
              port: 7860
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
          readinessProbe:
            httpGet:
              path: /
              port: 7860
            initialDelaySeconds: 15
            periodSeconds: 5
            timeoutSeconds: 3
      volumes:
        - name: benchmark-results
          persistentVolumeClaim:
            claimName: guidellm-results
---
# --- Service ---
apiVersion: v1
kind: Service
metadata:
  name: vllm-playground
  namespace: private-ai
  labels:
    app: vllm-playground
    app.kubernetes.io/part-of: step-07-model-performance-metrics
  annotations:
    argocd.argoproj.io/sync-wave: "12"
spec:
  ports:
    - name: http
      port: 7860
      targetPort: 7860
      protocol: TCP
  selector:
    app: vllm-playground
  type: ClusterIP
---
# --- Route ---
apiVersion: route.openshift.io/v1
kind: Route
metadata:
  name: vllm-playground
  namespace: private-ai
  labels:
    app: vllm-playground
    app.kubernetes.io/part-of: step-07-model-performance-metrics
  annotations:
    argocd.argoproj.io/sync-wave: "13"
spec:
  to:
    kind: Service
    name: vllm-playground
    weight: 100
  port:
    targetPort: http
  tls:
    termination: edge
    insecureEdgeTerminationPolicy: Redirect
  wildcardPolicy: None
