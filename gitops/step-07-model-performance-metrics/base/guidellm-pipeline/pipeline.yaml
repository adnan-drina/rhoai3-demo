# GuideLLM Benchmark Pipeline
# ============================================================================
# Orchestrates GuideLLM benchmarks with flexible configuration.
#
# Recommended configurations:
#
#   Daily Breaking Point Analysis (sweep + synthetic):
#     profile: sweep
#     rate: "5"
#     data-type: synthetic
#     prompt-tokens: "256"
#     output-tokens: "256"
#
#   Realistic User Load Test (poisson + synthetic):
#     profile: poisson
#     rate: "10"
#     data-type: synthetic
#
#   Quick Smoke Test (constant + prompts):
#     profile: constant
#     rate: "5"
#     data-type: prompts
#
# ============================================================================
apiVersion: tekton.dev/v1
kind: Pipeline
metadata:
  name: guidellm-benchmark
  namespace: private-ai
  labels:
    app: guidellm-pipeline
    app.kubernetes.io/part-of: benchmarking
  annotations:
    argocd.argoproj.io/sync-wave: "11"
    argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
spec:
  description: |
    GuideLLM Benchmark Pipeline for evaluating LLM inference performance.
    
    Measures key metrics:
    - Time To First Token (TTFT)
    - Time Per Output Token (TPOT)
    - Request Throughput
    - Latency distributions
    - KV Cache utilization
    
    Results are stored in the pipeline workspace.
  
  params:
    - name: model-name
      type: string
      description: Name of the model to benchmark
    
    - name: target-url
      type: string
      description: Model endpoint URL (leave empty for auto-discovery)
      default: ""
    
    - name: profile
      type: string
      description: |
        Benchmark profile:
        - sweep: Automatic exploration (recommended)
        - poisson: Realistic user load
        - constant: Fixed request rate
        - throughput: Maximum capacity
      default: "sweep"
    
    - name: rate
      type: string
      description: Rate parameter (meaning depends on profile)
      default: "5"
    
    - name: data-type
      type: string
      description: "Data source: synthetic (recommended) or prompts"
      default: "synthetic"
    
    - name: prompt-tokens
      type: string
      description: Input tokens for synthetic data
      default: "256"
    
    - name: output-tokens
      type: string
      description: Output tokens for synthetic data
      default: "256"
    
    - name: processor
      type: string
      description: HuggingFace tokenizer for synthetic data
      default: "mistralai/Mistral-Small-3.1-24B-Instruct-2503"
    
    - name: max-seconds
      type: string
      description: Maximum seconds per benchmark strategy
      default: "180"
    
    - name: max-requests
      type: string
      description: Maximum requests per benchmark strategy
      default: "150"
  
  workspaces:
    - name: results
      description: Workspace for storing benchmark results
  
  results:
    - name: output-file
      description: Path to the benchmark results
      value: $(tasks.benchmark.results.output-file)
    - name: status
      description: Benchmark status
      value: $(tasks.benchmark.results.status)
  
  tasks:
    - name: benchmark
      taskRef:
        name: guidellm-benchmark
      params:
        - name: model-name
          value: $(params.model-name)
        - name: target-url
          value: $(params.target-url)
        - name: profile
          value: $(params.profile)
        - name: rate
          value: $(params.rate)
        - name: data-type
          value: $(params.data-type)
        - name: prompt-tokens
          value: $(params.prompt-tokens)
        - name: output-tokens
          value: $(params.output-tokens)
        - name: processor
          value: $(params.processor)
        - name: max-seconds
          value: $(params.max-seconds)
        - name: max-requests
          value: $(params.max-requests)
      workspaces:
        - name: results
          workspace: results
