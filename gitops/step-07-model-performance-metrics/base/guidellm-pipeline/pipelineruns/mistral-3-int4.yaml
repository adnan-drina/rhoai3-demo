# GuideLLM Benchmark PipelineRun - Mistral-3 INT4 (1-GPU)
# ============================================================================
# Sweep profile with synthetic data for comprehensive performance analysis.
#
# Expected results (from testing):
#   - Baseline (sync): TTFT ~260ms, TPOT ~53ms
#   - Optimal: 5-11 concurrent, TTFT ~370ms, TPOT ~70ms
#   - Breaking point: 80+ concurrent, TTFT 26s, KV cache 99%
#
# Run manually:
#   oc create -f mistral-3-int4.yaml
# ============================================================================
apiVersion: tekton.dev/v1
kind: PipelineRun
metadata:
  generateName: benchmark-mistral-3-int4-
  namespace: private-ai
  labels:
    app: guidellm-pipeline
    model: mistral-3-int4
    app.kubernetes.io/part-of: benchmarking
spec:
  pipelineRef:
    name: guidellm-benchmark
  
  params:
    - name: model-name
      value: "mistral-3-int4"
    # Sweep profile: automatic exploration of performance envelope
    - name: profile
      value: "sweep"
    - name: rate
      value: "5"
    # Synthetic data: controlled workload (256 input + 256 output tokens)
    - name: data-type
      value: "synthetic"
    - name: prompt-tokens
      value: "256"
    - name: output-tokens
      value: "256"
    - name: processor
      value: "mistralai/Mistral-Small-3.1-24B-Instruct-2503"
    # Duration settings
    - name: max-seconds
      value: "180"
    - name: max-requests
      value: "150"
  
  workspaces:
    # Use emptyDir to avoid affinity-assistant scheduling issues
    - name: results
      emptyDir: {}
  
  # Schedule on CPU-only nodes (via cpu-workloads LocalQueue)
  taskRunSpecs:
    - pipelineTaskName: benchmark
      metadata:
        labels:
          kueue.x-k8s.io/queue-name: cpu-workloads
