# GuideLLM Benchmark PipelineRun - Mistral-3 BF16 (4-GPU)
# ============================================================================
# Sweep profile with synthetic data for comprehensive performance analysis.
#
# Expected results:
#   - Higher throughput capacity than INT4 due to 4 GPUs
#   - Lower KV cache pressure
#   - Better handling of high concurrency
#
# Run manually:
#   oc create -f mistral-3-bf16.yaml
# ============================================================================
apiVersion: tekton.dev/v1
kind: PipelineRun
metadata:
  generateName: benchmark-mistral-3-bf16-
  namespace: private-ai
  labels:
    app: guidellm-pipeline
    model: mistral-3-bf16
    app.kubernetes.io/part-of: benchmarking
spec:
  pipelineRef:
    name: guidellm-benchmark
  
  params:
    - name: model-name
      value: "mistral-3-bf16"
    # Sweep profile: automatic exploration of performance envelope
    - name: profile
      value: "sweep"
    - name: rate
      value: "5"
    # Synthetic data: controlled workload (256 input + 256 output tokens)
    - name: data-type
      value: "synthetic"
    - name: prompt-tokens
      value: "256"
    - name: output-tokens
      value: "256"
    - name: processor
      value: "mistralai/Mistral-Small-3.1-24B-Instruct-2503"
    # Duration settings
    - name: max-seconds
      value: "180"
    - name: max-requests
      value: "150"
  
  workspaces:
    # Use emptyDir to avoid affinity-assistant scheduling issues
    - name: results
      emptyDir: {}
  
  # Schedule on CPU-only nodes (via cpu-workloads LocalQueue)
  taskRunSpecs:
    - pipelineTaskName: benchmark
      metadata:
        labels:
          kueue.x-k8s.io/queue-name: cpu-workloads
