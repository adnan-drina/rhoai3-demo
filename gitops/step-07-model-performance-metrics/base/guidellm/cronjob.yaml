# GuideLLM Daily Benchmark CronJob - Sweep Profile with Synthetic Data
# ============================================================================
# Daily benchmark using sweep profile to automatically find:
#   1. Baseline performance (synchronous - one request at a time)
#   2. Maximum throughput capacity (throughput - as fast as possible)
#   3. Graduated load testing (constant rates - increasing concurrency)
#
# Synthetic Data Configuration:
#   - Input tokens: 256 (controlled prompt length)
#   - Output tokens: 256 (controlled generation length)
#   - Processor: mistralai/Mistral-Small-3.1-24B-Instruct-2503
#
# This configuration successfully found breaking points in testing:
#   - INT4 (1-GPU): Saturates at ~100 concurrent, KV cache 99%, TTFT 36s
#   - BF16 (4-GPU): Handles high load with minimal degradation
#
# Default: Daily at 2:00 AM UTC
#
# To trigger manually:
#   oc create job --from=cronjob/guidellm-daily manual-$(date +%H%M) -n private-ai
#
# Breaking Point Indicators (from Grafana):
#   - TTFT (p95) > 1.0s: Performance degradation
#   - KV Cache > 95%: Memory pressure
#   - Queue Waiting > 0: System saturated
# ============================================================================
apiVersion: batch/v1
kind: CronJob
metadata:
  name: guidellm-daily
  namespace: private-ai
  labels:
    app: guidellm
    app.kubernetes.io/part-of: benchmarking
  annotations:
    argocd.argoproj.io/sync-wave: "10"
spec:
  schedule: "0 2 * * *"
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      backoffLimit: 1
      activeDeadlineSeconds: 300
      template:
        metadata:
          labels:
            app: guidellm
            job-type: dispatcher
        spec:
          serviceAccountName: guidellm-dispatcher
          restartPolicy: Never
          containers:
            - name: dispatcher
              image: image-registry.openshift-image-registry.svc:5000/openshift/cli:latest
              env:
                - name: NAMESPACE
                  value: private-ai
                - name: GUIDELLM_IMAGE
                  value: ghcr.io/vllm-project/guidellm:stable
                # Sweep profile: Automatic rate exploration
                - name: GUIDELLM_PROFILE
                  value: sweep
                - name: GUIDELLM_SWEEP_SIZE
                  value: "5"
                # Synthetic data for controlled workload
                - name: GUIDELLM_PROMPT_TOKENS
                  value: "256"
                - name: GUIDELLM_OUTPUT_TOKENS
                  value: "256"
                # Tokenizer for synthetic data generation
                - name: GUIDELLM_PROCESSOR
                  value: "mistralai/Mistral-Small-3.1-24B-Instruct-2503"
                # Duration and limits
                - name: GUIDELLM_MAX_SECONDS
                  value: "180"
                - name: GUIDELLM_MAX_REQUESTS
                  value: "150"
              command:
                - /bin/bash
                - -c
                - |
                  set -e
                  TIMESTAMP=$(date +%Y%m%d-%H%M%S)
                  
                  echo "╔═══════════════════════════════════════════════════════════════════╗"
                  echo "║  GuideLLM Daily Benchmark - Sweep Profile                         ║"
                  echo "║  Timestamp: ${TIMESTAMP}                                          ║"
                  echo "╠═══════════════════════════════════════════════════════════════════╣"
                  echo "║  Profile: sweep (automatic rate exploration)                      ║"
                  echo "║  Data: synthetic (${GUIDELLM_PROMPT_TOKENS} in, ${GUIDELLM_OUTPUT_TOKENS} out tokens)              ║"
                  echo "║  Processor: ${GUIDELLM_PROCESSOR}     ║"
                  echo "╚═══════════════════════════════════════════════════════════════════╝"
                  echo ""
                  
                  # Models to benchmark
                  MODELS="mistral-3-int4 mistral-3-bf16"
                  CREATED_JOBS=""
                  
                  for MODEL in ${MODELS}; do
                    TARGET="http://${MODEL}-predictor.private-ai.svc.cluster.local:8080/v1"
                    JOB_NAME="guidellm-${MODEL}-${TIMESTAMP}"
                    
                    echo "───────────────────────────────────────────────────────────────────"
                    echo "  Model: ${MODEL}"
                    echo "  Target: ${TARGET}"
                    echo "───────────────────────────────────────────────────────────────────"
                    
                    # Check if model is available
                    if ! curl -s --connect-timeout 10 "${TARGET}/models" >/dev/null 2>&1; then
                      echo "  ⚠️  Model ${MODEL} is not reachable, skipping"
                      continue
                    fi
                    echo "  ✓ Model is reachable"
                    
                    # Create Job YAML file
                    cat > /tmp/job-${MODEL}.yaml << JOBEOF
                  apiVersion: batch/v1
                  kind: Job
                  metadata:
                    name: ${JOB_NAME}
                    namespace: ${NAMESPACE}
                    labels:
                      app: guidellm
                      model: ${MODEL}
                      benchmark-run: "${TIMESTAMP}"
                      profile: sweep
                  spec:
                    backoffLimit: 1
                    activeDeadlineSeconds: 1800
                    ttlSecondsAfterFinished: 86400
                    template:
                      metadata:
                        labels:
                          app: guidellm
                          model: ${MODEL}
                      spec:
                        restartPolicy: Never
                        dnsPolicy: ClusterFirst
                        containers:
                          - name: benchmark
                            image: ${GUIDELLM_IMAGE}
                            env:
                              - name: HOME
                                value: /tmp
                              - name: HF_HOME
                                value: /tmp/.cache/huggingface
                              - name: MODEL_NAME
                                value: ${MODEL}
                              - name: TARGET_URL
                                value: ${TARGET}
                              - name: PROFILE
                                value: ${GUIDELLM_PROFILE}
                              - name: SWEEP_SIZE
                                value: "${GUIDELLM_SWEEP_SIZE}"
                              - name: PROMPT_TOKENS
                                value: "${GUIDELLM_PROMPT_TOKENS}"
                              - name: OUTPUT_TOKENS
                                value: "${GUIDELLM_OUTPUT_TOKENS}"
                              - name: PROCESSOR
                                value: "${GUIDELLM_PROCESSOR}"
                              - name: MAX_SECONDS
                                value: "${GUIDELLM_MAX_SECONDS}"
                              - name: MAX_REQUESTS
                                value: "${GUIDELLM_MAX_REQUESTS}"
                              - name: TIMESTAMP
                                value: "${TIMESTAMP}"
                            command:
                              - /bin/bash
                              - -c
                              - |
                                echo "╔═══════════════════════════════════════════════════════════════════╗"
                                echo "║  GuideLLM Benchmark: \${MODEL_NAME}"
                                echo "╠═══════════════════════════════════════════════════════════════════╣"
                                echo "║  Target: \${TARGET_URL}"
                                echo "║  Profile: \${PROFILE} (sweep_size: \${SWEEP_SIZE})"
                                echo "║  Data: synthetic (\${PROMPT_TOKENS} input, \${OUTPUT_TOKENS} output tokens)"
                                echo "║  Processor: \${PROCESSOR}"
                                echo "╚═══════════════════════════════════════════════════════════════════╝"
                                echo ""
                                
                                # ============================================================
                                # FIX: Resolve DNS to IP before running GuideLLM
                                # GuideLLM uses Python multiprocessing which forks workers.
                                # Forked workers cannot resolve DNS (known container issue).
                                # Solution: Resolve DNS now and use IP-based URL.
                                # ============================================================
                                
                                HOSTNAME=\$(echo "\${TARGET_URL}" | sed -E 's|https?://([^:/]+).*|\1|')
                                echo "Resolving DNS for: \${HOSTNAME}"
                                
                                IP=\$(getent hosts "\${HOSTNAME}" 2>/dev/null | awk '{print \$1}' | head -1)
                                
                                if [ -z "\${IP}" ]; then
                                  echo "Warning: Could not resolve \${HOSTNAME}, trying nslookup..."
                                  IP=\$(nslookup "\${HOSTNAME}" 2>/dev/null | grep -A1 'Name:' | grep 'Address:' | awk '{print \$2}' | head -1)
                                fi
                                
                                if [ -z "\${IP}" ]; then
                                  echo "Warning: DNS resolution failed, using original URL"
                                  RESOLVED_URL="\${TARGET_URL}"
                                else
                                  RESOLVED_URL=\$(echo "\${TARGET_URL}" | sed "s|\${HOSTNAME}|\${IP}|")
                                  echo "✓ Resolved: \${TARGET_URL} -> \${RESOLVED_URL}"
                                fi
                                
                                echo ""
                                echo "Starting sweep benchmark..."
                                echo ""
                                
                                guidellm benchmark run \
                                  --target "\${RESOLVED_URL}" \
                                  --profile "\${PROFILE}" \
                                  --rate "\${SWEEP_SIZE}" \
                                  --processor "\${PROCESSOR}" \
                                  --data "prompt_tokens=\${PROMPT_TOKENS},output_tokens=\${OUTPUT_TOKENS}" \
                                  --max-seconds "\${MAX_SECONDS}" \
                                  --max-requests "\${MAX_REQUESTS}" \
                                  --output-dir /results \
                                  --disable-console-interactive
                                
                                echo ""
                                echo "════════════════════════════════════════════════════════════════════"
                                echo "  Benchmark complete for \${MODEL_NAME}"
                                echo "════════════════════════════════════════════════════════════════════"
                            volumeMounts:
                              - name: results
                                mountPath: /results
                              - name: cache
                                mountPath: /tmp/.cache
                            resources:
                              requests:
                                cpu: 500m
                                memory: 1Gi
                              limits:
                                cpu: "2"
                                memory: 4Gi
                        volumes:
                          - name: results
                            persistentVolumeClaim:
                              claimName: guidellm-results
                          - name: cache
                            emptyDir: {}
                  JOBEOF
                    
                    # Apply the Job
                    oc apply -f /tmp/job-${MODEL}.yaml
                    
                    echo "  ✓ Created Job: ${JOB_NAME}"
                    CREATED_JOBS="${CREATED_JOBS} ${JOB_NAME}"
                    echo ""
                  done
                  
                  echo "═══════════════════════════════════════════════════════════════════"
                  echo "  Dispatcher complete!"
                  echo "  Created Jobs:${CREATED_JOBS}"
                  echo ""
                  echo "  Monitor with:"
                  echo "    oc get jobs -n ${NAMESPACE} -l benchmark-run=${TIMESTAMP}"
                  echo ""
                  echo "  View results in Grafana:"
                  echo "    Dashboard: Mistral 3 (BF16 vs INT4)"
                  echo "═══════════════════════════════════════════════════════════════════"
              resources:
                requests:
                  cpu: 100m
                  memory: 128Mi
                limits:
                  cpu: 500m
                  memory: 256Mi
