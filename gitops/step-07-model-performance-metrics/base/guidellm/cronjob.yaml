# GuideLLM Parallel Benchmark CronJob
# ============================================================================
# Spawns parallel benchmark Jobs for each model.
# Each model runs in its own container/Job for true parallelism.
#
# Default: Daily at 2:00 AM UTC
#
# To trigger manually:
#   oc create job --from=cronjob/guidellm-daily manual-$(date +%H%M) -n private-ai
#
# The dispatcher creates individual Jobs for each available model:
#   - guidellm-mistral-3-int4-<timestamp>
#   - guidellm-mistral-3-bf16-<timestamp>
# ============================================================================
apiVersion: batch/v1
kind: CronJob
metadata:
  name: guidellm-daily
  namespace: private-ai
  labels:
    app: guidellm
    app.kubernetes.io/part-of: benchmarking
  annotations:
    argocd.argoproj.io/sync-wave: "10"
spec:
  schedule: "0 2 * * *"
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      backoffLimit: 1
      activeDeadlineSeconds: 300
      template:
        metadata:
          labels:
            app: guidellm
            job-type: dispatcher
        spec:
          serviceAccountName: guidellm-dispatcher
          restartPolicy: Never
          containers:
            - name: dispatcher
              image: image-registry.openshift-image-registry.svc:5000/openshift/cli:latest
              env:
                - name: NAMESPACE
                  value: private-ai
                - name: GUIDELLM_IMAGE
                  value: ghcr.io/vllm-project/guidellm:stable
                - name: GUIDELLM_PROFILE
                  value: sweep
                - name: GUIDELLM_MAX_SECONDS
                  value: "60"
                - name: GUIDELLM_MAX_REQUESTS
                  value: "50"
              command:
                - /bin/bash
                - -c
                - |
                  set -e
                  # Use hyphen instead of underscore for K8s-compatible names
                  TIMESTAMP=$(date +%Y%m%d-%H%M%S)
                  
                  echo "╔═══════════════════════════════════════════════════════════════════╗"
                  echo "║  GuideLLM Parallel Benchmark Dispatcher                           ║"
                  echo "║  Timestamp: ${TIMESTAMP}                                          ║"
                  echo "╚═══════════════════════════════════════════════════════════════════╝"
                  echo ""
                  
                  # Models to benchmark
                  MODELS="mistral-3-int4 mistral-3-bf16"
                  CREATED_JOBS=""
                  
                  for MODEL in ${MODELS}; do
                    TARGET="http://${MODEL}-predictor.private-ai.svc.cluster.local:8080/v1"
                    JOB_NAME="guidellm-${MODEL}-${TIMESTAMP}"
                    
                    echo "───────────────────────────────────────────────────────────────────"
                    echo "  Model: ${MODEL}"
                    echo "  Target: ${TARGET}"
                    echo "───────────────────────────────────────────────────────────────────"
                    
                    # Check if model is available
                    if ! curl -s --connect-timeout 10 "${TARGET}/models" >/dev/null 2>&1; then
                      echo "  ⚠️  Model ${MODEL} is not reachable, skipping"
                      continue
                    fi
                    echo "  ✓ Model is reachable"
                    
                    # Create Job YAML file
                    cat > /tmp/job-${MODEL}.yaml << JOBEOF
                  apiVersion: batch/v1
                  kind: Job
                  metadata:
                    name: ${JOB_NAME}
                    namespace: ${NAMESPACE}
                    labels:
                      app: guidellm
                      model: ${MODEL}
                      benchmark-run: "${TIMESTAMP}"
                  spec:
                    backoffLimit: 1
                    activeDeadlineSeconds: 900
                    ttlSecondsAfterFinished: 86400
                    template:
                      metadata:
                        labels:
                          app: guidellm
                          model: ${MODEL}
                      spec:
                        restartPolicy: Never
                        dnsPolicy: ClusterFirst
                        securityContext:
                          fsGroup: 0
                        containers:
                          - name: benchmark
                            image: ${GUIDELLM_IMAGE}
                            env:
                              - name: HOME
                                value: /tmp
                              - name: HF_HOME
                                value: /tmp/.cache/huggingface
                              - name: MODEL_NAME
                                value: ${MODEL}
                              - name: TARGET_URL
                                value: ${TARGET}
                              - name: PROFILE
                                value: ${GUIDELLM_PROFILE}
                              - name: MAX_SECONDS
                                value: "${GUIDELLM_MAX_SECONDS}"
                              - name: MAX_REQUESTS
                                value: "${GUIDELLM_MAX_REQUESTS}"
                              - name: TIMESTAMP
                                value: "${TIMESTAMP}"
                            command:
                              - /bin/bash
                              - -c
                              - |
                                echo "GuideLLM Benchmark: \${MODEL_NAME}"
                                echo "Target: \${TARGET_URL}"
                                echo "Profile: \${PROFILE}"
                                
                                # ============================================================
                                # FIX: Resolve DNS to IP before running GuideLLM
                                # GuideLLM uses Python multiprocessing which forks workers.
                                # Forked workers cannot resolve DNS (known container issue).
                                # Solution: Resolve DNS now and use IP-based URL.
                                # ============================================================
                                
                                # Extract hostname from TARGET_URL
                                HOSTNAME=\$(echo "\${TARGET_URL}" | sed -E 's|https?://([^:/]+).*|\1|')
                                echo "Resolving DNS for: \${HOSTNAME}"
                                
                                # Resolve hostname to IP using getent (works in most containers)
                                IP=\$(getent hosts "\${HOSTNAME}" 2>/dev/null | awk '{print \$1}' | head -1)
                                
                                if [ -z "\${IP}" ]; then
                                  echo "Warning: Could not resolve \${HOSTNAME}, trying nslookup..."
                                  IP=\$(nslookup "\${HOSTNAME}" 2>/dev/null | grep -A1 'Name:' | grep 'Address:' | awk '{print \$2}' | head -1)
                                fi
                                
                                if [ -z "\${IP}" ]; then
                                  echo "Warning: DNS resolution failed, using original URL"
                                  RESOLVED_URL="\${TARGET_URL}"
                                else
                                  # Replace hostname with IP in the URL
                                  RESOLVED_URL=\$(echo "\${TARGET_URL}" | sed "s|\${HOSTNAME}|\${IP}|")
                                  echo "Resolved: \${TARGET_URL} -> \${RESOLVED_URL}"
                                fi
                                
                                cat > /tmp/prompts.json << 'EOF'
                                [{"prompt": "What is the capital of France?"},{"prompt": "Explain quantum computing."},{"prompt": "Write a poem about the ocean."},{"prompt": "What are benefits of exercise?"},{"prompt": "How does photosynthesis work?"},{"prompt": "What is machine learning?"},{"prompt": "Tell me about the solar system."},{"prompt": "What causes rain?"},{"prompt": "Explain the theory of relativity."},{"prompt": "Describe making bread."}]
                                EOF
                                
                                guidellm benchmark run \
                                  --target "\${RESOLVED_URL}" \
                                  --data /tmp/prompts.json \
                                  --profile "\${PROFILE}" \
                                  --max-seconds "\${MAX_SECONDS}" \
                                  --max-requests "\${MAX_REQUESTS}" \
                                  --output-dir /results \
                                  --outputs "\${MODEL_NAME}-\${TIMESTAMP}.json" \
                                  --disable-console-interactive
                                
                                echo "Benchmark complete for \${MODEL_NAME}"
                            volumeMounts:
                              - name: results
                                mountPath: /results
                              - name: cache
                                mountPath: /tmp/.cache
                            resources:
                              requests:
                                cpu: 500m
                                memory: 512Mi
                              limits:
                                cpu: "2"
                                memory: 2Gi
                        volumes:
                          - name: results
                            persistentVolumeClaim:
                              claimName: guidellm-results
                          - name: cache
                            emptyDir: {}
                  JOBEOF
                    
                    # Apply the Job
                    oc apply -f /tmp/job-${MODEL}.yaml
                    
                    echo "  ✓ Created Job: ${JOB_NAME}"
                    CREATED_JOBS="${CREATED_JOBS} ${JOB_NAME}"
                    echo ""
                  done
                  
                  echo "═══════════════════════════════════════════════════════════════════"
                  echo "  Dispatcher complete!"
                  echo "  Created Jobs:${CREATED_JOBS}"
                  echo ""
                  echo "  Monitor with:"
                  echo "    oc get jobs -n ${NAMESPACE} -l benchmark-run=${TIMESTAMP}"
                  echo "═══════════════════════════════════════════════════════════════════"
              resources:
                requests:
                  cpu: 100m
                  memory: 128Mi
                limits:
                  cpu: 500m
                  memory: 256Mi
