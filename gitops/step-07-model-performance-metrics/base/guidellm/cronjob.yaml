# GuideLLM Daily Benchmark CronJob - Graduated Concurrency Testing
# ============================================================================
# Daily benchmark using constant profile with graduated concurrency levels.
#
# Concurrency Ramp-Up Strategy (post-optimization):
#   1 → 3 → 5 → 8 → 10 → 15 → 20 → 30
#   │   │   │   │    │    │    │    └── BF16 breaking point
#   │   │   │   │    │    │    └─────── BF16 sweet spot boundary
#   │   │   │   │    │    └──────────── INT4 new breaking point (with FP8 cache)
#   │   │   │   │    └───────────────── INT4 new SLA breach (with FP8 cache)
#   │   │   │   └────────────────────── INT4 target capacity (2x improvement)
#   │   │   └────────────────────────── INT4 old breaking point (before FP8)
#   │   └────────────────────────────── Baseline warmup
#   └────────────────────────────────── Single user baseline
#
# Optimizations applied to INT4:
#   --kv-cache-dtype=fp8      → Doubles KV cache capacity
#   --max-model-len=8192      → Sweet spot for L4
#   --enable-chunked-prefill  → Stabilizes TTFT
#   --gpu-memory-utilization=0.85
#
# Synthetic Data Configuration:
#   - Input tokens: 256 (controlled prompt length)
#   - Output tokens: 256 (controlled generation length)
#   - Processor: mistralai/Mistral-Small-3.1-24B-Instruct-2503
#
# Expected Results (post-optimization):
#   - INT4 (1-GPU + FP8 cache): Target 8 concurrent users (2x improvement)
#     - SLA threshold: ~10 concurrent (TTFT < 1s)
#     - Breaking point: ~15 concurrent
#   - BF16 (4-GPU): Optimal 1-20 concurrent, TTFT breaks at 30+ (>2s)
#
# Key Performance Targets:
#   INT4: 8 concurrent users @ >150 tok/s (optimization story)
#   BF16: 20 concurrent users @ >300 tok/s (capacity story)
#
# Default: Daily at 2:00 AM UTC
#
# To trigger manually:
#   oc create job --from=cronjob/guidellm-daily manual-$(date +%H%M) -n private-ai
#
# Breaking Point Indicators (from Grafana):
#   - TTFT (p95) > 1.0s: Performance degradation
#   - KV Cache > 95%: Memory pressure
#   - Queue Waiting > 0: System saturated
# ============================================================================
apiVersion: batch/v1
kind: CronJob
metadata:
  name: guidellm-daily
  namespace: private-ai
  labels:
    app: guidellm
    app.kubernetes.io/part-of: benchmarking
  annotations:
    argocd.argoproj.io/sync-wave: "10"
spec:
  schedule: "0 2 * * *"
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      backoffLimit: 1
      activeDeadlineSeconds: 300
      template:
        metadata:
          labels:
            app: guidellm
            job-type: dispatcher
        spec:
          serviceAccountName: guidellm-dispatcher
          restartPolicy: Never
          containers:
            - name: dispatcher
              image: image-registry.openshift-image-registry.svc:5000/openshift/cli:latest
              env:
                - name: NAMESPACE
                  value: private-ai
                - name: GUIDELLM_IMAGE
                  value: ghcr.io/vllm-project/guidellm:stable
                # Constant profile with graduated concurrency levels
                - name: GUIDELLM_PROFILE
                  value: constant
                # Linear staircase: find new breaking points after FP8 cache optimization
                - name: GUIDELLM_RATES
                  value: "1,3,5,8,10,15,20,30"
                - name: GUIDELLM_RATE_TYPE
                  value: concurrent
                # Synthetic data for controlled workload
                - name: GUIDELLM_PROMPT_TOKENS
                  value: "256"
                - name: GUIDELLM_OUTPUT_TOKENS
                  value: "256"
                # Tokenizer for synthetic data generation
                - name: GUIDELLM_PROCESSOR
                  value: "mistralai/Mistral-Small-3.1-24B-Instruct-2503"
                # Duration per concurrency level (10 levels × 60s = ~10 min per model)
                - name: GUIDELLM_MAX_SECONDS
                  value: "60"
                - name: GUIDELLM_MAX_REQUESTS
                  value: "100"
              command:
                - /bin/bash
                - -c
                - |
                  set -e
                  TIMESTAMP=$(date +%Y%m%d-%H%M%S)
                  
                  echo "╔═══════════════════════════════════════════════════════════════════╗"
                  echo "║  GuideLLM Daily Benchmark - Graduated Concurrency                 ║"
                  echo "║  Timestamp: ${TIMESTAMP}                                          ║"
                  echo "╠═══════════════════════════════════════════════════════════════════╣"
                  echo "║  Profile: ${GUIDELLM_PROFILE} (${GUIDELLM_RATE_TYPE})"
                  echo "║  Rates: ${GUIDELLM_RATES}"
                  echo "║  Data: synthetic (${GUIDELLM_PROMPT_TOKENS} in, ${GUIDELLM_OUTPUT_TOKENS} out tokens)"
                  echo "║  Duration: ${GUIDELLM_MAX_SECONDS}s per level, ${GUIDELLM_MAX_REQUESTS} max requests"
                  echo "╚═══════════════════════════════════════════════════════════════════╝"
                  echo ""
                  
                  # Models to benchmark
                  MODELS="mistral-3-int4 mistral-3-bf16"
                  CREATED_JOBS=""
                  
                  for MODEL in ${MODELS}; do
                    TARGET="http://${MODEL}-predictor.private-ai.svc.cluster.local:8080/v1"
                    JOB_NAME="guidellm-${MODEL}-${TIMESTAMP}"
                    
                    echo "───────────────────────────────────────────────────────────────────"
                    echo "  Model: ${MODEL}"
                    echo "  Target: ${TARGET}"
                    echo "───────────────────────────────────────────────────────────────────"
                    
                    # Check if model is available
                    if ! curl -s --connect-timeout 10 "${TARGET}/models" >/dev/null 2>&1; then
                      echo "  ⚠️  Model ${MODEL} is not reachable, skipping"
                      continue
                    fi
                    echo "  ✓ Model is reachable"
                    
                    # Create Job YAML file
                    cat > /tmp/job-${MODEL}.yaml << JOBEOF
                  apiVersion: batch/v1
                  kind: Job
                  metadata:
                    name: ${JOB_NAME}
                    namespace: ${NAMESPACE}
                    labels:
                      app: guidellm
                      model: ${MODEL}
                      benchmark-run: "${TIMESTAMP}"
                      profile: sweep
                  spec:
                    backoffLimit: 1
                    # 10 concurrency levels × 60s each + overhead = ~15 min
                    activeDeadlineSeconds: 1200
                    ttlSecondsAfterFinished: 86400
                    template:
                      metadata:
                        labels:
                          app: guidellm
                          model: ${MODEL}
                      spec:
                        restartPolicy: Never
                        dnsPolicy: ClusterFirst
                        containers:
                          - name: benchmark
                            image: ${GUIDELLM_IMAGE}
                            env:
                              - name: HOME
                                value: /tmp
                              - name: HF_HOME
                                value: /tmp/.cache/huggingface
                              - name: MODEL_NAME
                                value: ${MODEL}
                              - name: TARGET_URL
                                value: ${TARGET}
                              - name: PROFILE
                                value: ${GUIDELLM_PROFILE}
                              - name: RATES
                                value: "${GUIDELLM_RATES}"
                              - name: RATE_TYPE
                                value: "${GUIDELLM_RATE_TYPE}"
                              - name: PROMPT_TOKENS
                                value: "${GUIDELLM_PROMPT_TOKENS}"
                              - name: OUTPUT_TOKENS
                                value: "${GUIDELLM_OUTPUT_TOKENS}"
                              - name: PROCESSOR
                                value: "${GUIDELLM_PROCESSOR}"
                              - name: MAX_SECONDS
                                value: "${GUIDELLM_MAX_SECONDS}"
                              - name: MAX_REQUESTS
                                value: "${GUIDELLM_MAX_REQUESTS}"
                              - name: TIMESTAMP
                                value: "${TIMESTAMP}"
                            command:
                              - /bin/bash
                              - -c
                              - |
                                echo "╔═══════════════════════════════════════════════════════════════════╗"
                                echo "║  GuideLLM Benchmark: \${MODEL_NAME}"
                                echo "╠═══════════════════════════════════════════════════════════════════╣"
                                echo "║  Target: \${TARGET_URL}"
                                echo "║  Profile: \${PROFILE} (\${RATE_TYPE})"
                                echo "║  Rates: \${RATES}"
                                echo "║  Data: synthetic (\${PROMPT_TOKENS} input, \${OUTPUT_TOKENS} output tokens)"
                                echo "║  Processor: \${PROCESSOR}"
                                echo "╚═══════════════════════════════════════════════════════════════════╝"
                                echo ""
                                
                                # ============================================================
                                # FIX: Resolve DNS to IP before running GuideLLM
                                # GuideLLM uses Python multiprocessing which forks workers.
                                # Forked workers cannot resolve DNS (known container issue).
                                # Solution: Resolve DNS now and use IP-based URL.
                                # ============================================================
                                
                                HOSTNAME=\$(echo "\${TARGET_URL}" | sed -E 's|https?://([^:/]+).*|\1|')
                                echo "Resolving DNS for: \${HOSTNAME}"
                                
                                IP=\$(getent hosts "\${HOSTNAME}" 2>/dev/null | awk '{print \$1}' | head -1)
                                
                                if [ -z "\${IP}" ]; then
                                  echo "Warning: Could not resolve \${HOSTNAME}, trying nslookup..."
                                  IP=\$(nslookup "\${HOSTNAME}" 2>/dev/null | grep -A1 'Name:' | grep 'Address:' | awk '{print \$2}' | head -1)
                                fi
                                
                                if [ -z "\${IP}" ]; then
                                  echo "Warning: DNS resolution failed, using original URL"
                                  RESOLVED_URL="\${TARGET_URL}"
                                else
                                  RESOLVED_URL=\$(echo "\${TARGET_URL}" | sed "s|\${HOSTNAME}|\${IP}|")
                                  echo "✓ Resolved: \${TARGET_URL} -> \${RESOLVED_URL}"
                                fi
                                
                                echo ""
                                echo "Starting sweep benchmark..."
                                echo ""
                                
                                guidellm benchmark run \
                                  --target "\${RESOLVED_URL}" \
                                  --profile "\${PROFILE}" \
                                  --rate "\${RATES}" \
                                  --rate-type "\${RATE_TYPE}" \
                                  --processor "\${PROCESSOR}" \
                                  --data "prompt_tokens=\${PROMPT_TOKENS},output_tokens=\${OUTPUT_TOKENS}" \
                                  --max-seconds "\${MAX_SECONDS}" \
                                  --max-requests "\${MAX_REQUESTS}" \
                                  --output-dir /results \
                                  --disable-console-interactive
                                
                                echo ""
                                echo "════════════════════════════════════════════════════════════════════"
                                echo "  Benchmark complete for \${MODEL_NAME}"
                                echo "════════════════════════════════════════════════════════════════════"
                            volumeMounts:
                              - name: results
                                mountPath: /results
                              - name: cache
                                mountPath: /tmp/.cache
                            resources:
                              requests:
                                cpu: 500m
                                memory: 1Gi
                              limits:
                                cpu: "2"
                                memory: 4Gi
                        volumes:
                          - name: results
                            persistentVolumeClaim:
                              claimName: guidellm-results
                          - name: cache
                            emptyDir: {}
                  JOBEOF
                    
                    # Apply the Job
                    oc apply -f /tmp/job-${MODEL}.yaml
                    
                    echo "  ✓ Created Job: ${JOB_NAME}"
                    CREATED_JOBS="${CREATED_JOBS} ${JOB_NAME}"
                    echo ""
                  done
                  
                  echo "═══════════════════════════════════════════════════════════════════"
                  echo "  Dispatcher complete!"
                  echo "  Created Jobs:${CREATED_JOBS}"
                  echo ""
                  echo "  Monitor with:"
                  echo "    oc get jobs -n ${NAMESPACE} -l benchmark-run=${TIMESTAMP}"
                  echo ""
                  echo "  View results in Grafana:"
                  echo "    Dashboard: Mistral 3 (BF16 vs INT4)"
                  echo "═══════════════════════════════════════════════════════════════════"
              resources:
                requests:
                  cpu: 100m
                  memory: 128Mi
                limits:
                  cpu: 500m
                  memory: 256Mi
