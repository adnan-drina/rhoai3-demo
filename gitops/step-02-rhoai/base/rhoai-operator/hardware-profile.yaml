# HardwareProfile - GPU Profile for Model Serving & GenAI Studio
# Ref: https://rhpds.github.io/redhat-openshift-ai-3-showroom/modules/03-02-hardware-profile.html
# Ref: https://docs.redhat.com/en/documentation/red_hat_openshift_ai_self-managed/3.0/html-single/working_with_accelerators/index#working-with-hardware-profiles
apiVersion: infrastructure.opendatahub.io/v1
kind: HardwareProfile
metadata:
  name: gpu-profile
  namespace: redhat-ods-applications
  annotations:
    argocd.argoproj.io/sync-wave: "16"
    argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
    opendatahub.io/display-name: "NVIDIA L4 GPU Profile"
    opendatahub.io/description: "Hardware profile for AWS G6 instances with NVIDIA L4 GPUs"
    opendatahub.io/disabled: "false"
  labels:
    app.kubernetes.io/part-of: hardwareprofile
    app.opendatahub.io/hardwareprofile: "true"
spec:
  # Scheduling configuration - target GPU nodes with tolerations
  scheduling:
    type: Node
    node:
      # Target GPU nodes created by step-01-gpu MachineSets
      nodeSelector:
        node-role.kubernetes.io/gpu: ""
      # Tolerate GPU taints to schedule on reserved GPU nodes
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
  
  # Resource identifiers
  identifiers:
    # CPU allocation
    - identifier: cpu
      displayName: CPU
      resourceType: CPU
      minCount: 1
      maxCount: "8"
      defaultCount: "2"
    
    # Memory allocation
    - identifier: memory
      displayName: Memory
      resourceType: Memory
      minCount: 4Gi
      maxCount: 64Gi
      defaultCount: 16Gi
    
    # GPU allocation (NVIDIA L4 on AWS G6 instances)
    - identifier: nvidia.com/gpu
      displayName: NVIDIA L4 GPU
      resourceType: Accelerator
      minCount: 1
      maxCount: 4
      defaultCount: 1
