# HardwareProfile - NVIDIA L4 4GPUs (AWS g6.12xlarge)
# High-performance profile for multi-GPU workloads and large models
# Node specs: 48 vCPU, 192 GB RAM, 4x NVIDIA L4 GPU
apiVersion: infrastructure.opendatahub.io/v1
kind: HardwareProfile
metadata:
  name: nvidia-l4-4gpu
  namespace: redhat-ods-applications
  annotations:
    argocd.argoproj.io/sync-wave: "16"
    argocd.argoproj.io/sync-options: SkipDryRunOnMissingResource=true
    opendatahub.io/display-name: "NVIDIA L4 4GPUs"
    opendatahub.io/description: "AWS g6.12xlarge - 4x NVIDIA L4 GPUs for large models and distributed inference"
    opendatahub.io/disabled: "false"
  labels:
    app.kubernetes.io/part-of: hardwareprofile
    app.opendatahub.io/hardwareprofile: "true"
spec:
  # Scheduling - target g6.12xlarge nodes
  scheduling:
    type: Node
    node:
      nodeSelector:
        node-role.kubernetes.io/gpu: ""
        node.kubernetes.io/instance-type: g6.12xlarge
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
  
  # Resource identifiers (matching g6.12xlarge specs)
  identifiers:
    # CPU: g6.12xlarge has 48 vCPU
    - identifier: cpu
      displayName: CPU
      resourceType: CPU
      minCount: 1
      maxCount: "48"
      defaultCount: "24"
    
    # Memory: g6.12xlarge has 192 GB
    - identifier: memory
      displayName: Memory
      resourceType: Memory
      minCount: 8Gi
      maxCount: 192Gi
      defaultCount: 96Gi
    
    # GPU: g6.12xlarge has 4x NVIDIA L4
    - identifier: nvidia.com/gpu
      displayName: NVIDIA L4 GPU
      resourceType: Accelerator
      minCount: 1
      maxCount: 4
      defaultCount: 4

