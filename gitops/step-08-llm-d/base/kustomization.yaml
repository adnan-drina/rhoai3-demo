apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

# Step 08: Distributed Inference with llm-d
# Demonstrates horizontal scaling of LLM inference across multiple GPU nodes
#
# Architecture:
#   ┌─────────────────────────────────────────────────────────────────┐
#   │                    private-ai namespace                         │
#   ├─────────────────────────────────────────────────────────────────┤
#   │                                                                 │
#   │   ┌─────────────────┐     ┌─────────────────────────────────┐  │
#   │   │  llm-d Router   │◀────│        Gateway API              │  │
#   │   │  (scheduler)    │     │  (data-science-gateway)         │  │
#   │   └────────┬────────┘     └─────────────────────────────────┘  │
#   │            │                                                    │
#   │            ├───────────────────┐                               │
#   │            │                   │                               │
#   │            ▼                   ▼                               │
#   │   ┌────────────────┐  ┌────────────────┐                      │
#   │   │  Worker Pod 0  │  │  Worker Pod 1  │                      │
#   │   │  g6.4xlarge    │  │  g6.4xlarge    │                      │
#   │   │  1× NVIDIA L4  │  │  1× NVIDIA L4  │                      │
#   │   └────────────────┘  └────────────────┘                      │
#   │                                                                 │
#   └─────────────────────────────────────────────────────────────────┘
#
# Prerequisites:
#   - LeaderWorkerSet operator installed (Step 01)
#   - Red Hat Connectivity Link (RHCL) operator installed (Step 01)
#   - Gateway API configured (RHOAI 3.0 default)
#   - 2× g6.4xlarge GPU nodes available
#
# Ref: https://docs.redhat.com/en/documentation/red_hat_openshift_ai_self-managed/3.0/html-single/deploying_models/index

resources:
  # ═══════════════════════════════════════════════════════════════════════════
  # Gateway for llm-d (sync-wave: -1)
  # Dedicated Gateway allowing HTTPRoutes from private-ai namespace
  # The platform-managed data-science-gateway only allows openshift-ingress
  # and redhat-ods-applications namespaces by default
  # ═══════════════════════════════════════════════════════════════════════════
  - gateway/

  # ═══════════════════════════════════════════════════════════════════════════
  # Red Hat Connectivity Link (RHCL) instance (sync-wave: 0)
  # Required for llm-d Gateway integration and AuthPolicy validation
  # ═══════════════════════════════════════════════════════════════════════════
  - rhcl/
  
  # ═══════════════════════════════════════════════════════════════════════════
  # Distributed Inference Service (sync-wave: 1)
  # ═══════════════════════════════════════════════════════════════════════════
  - llm-d/
  
  # ═══════════════════════════════════════════════════════════════════════════
  # Benchmark Resources (sync-wave: 5)
  # Dedicated GuideLLM benchmark for distributed endpoint
  # ═══════════════════════════════════════════════════════════════════════════
  - benchmark/

