apiVersion: batch/v1
kind: Job
metadata:
  name: multi-turn-benchmark-vllm-int4
  namespace: private-ai
  labels:
    app.kubernetes.io/name: multi-turn-benchmark-vllm-int4
    app.kubernetes.io/component: benchmark
    app.kubernetes.io/part-of: llm-serving
    demo.rhoai.io/step: "08"
spec:
  backoffLimit: 0
  ttlSecondsAfterFinished: 86400
  template:
    metadata:
      labels:
        app.kubernetes.io/name: multi-turn-benchmark-vllm-int4
        app.kubernetes.io/component: benchmark
        demo.rhoai.io/step: "08"
    spec:
      restartPolicy: Never
      containers:
        - name: benchmark
          # Borrowed benchmark harness pattern from:
          # https://github.com/rh-aiservices-bu/rhaoi3-llm-d
          #
          # NOTE: This Job runs immediately when applied. Keep it in overlays/
          # and apply only when you want to execute the benchmark.
          image: quay.io/hayesphilip/multi-turn-benchmark:0.0.1
          args:
            # Baseline endpoint: Step 05/07 vLLM INT4 service (in-cluster)
            - "http://mistral-3-int4-predictor.private-ai.svc.cluster.local:8080/v1"
            - "--conversations"
            - "20"
            - "--turns"
            - "6"
            - "--max-tokens"
            - "150"
            - "--parallel"
            - "4"
            - "--min-delay"
            - "0.1"
            - "--max-delay"
            - "1.0"
            - "--timeout"
            - "120"
          resources:
            requests:
              cpu: "500m"
              memory: "512Mi"
            limits:
              cpu: "2"
              memory: "2Gi"


