# ClusterQueue - Cluster-wide resource quota pool
# Defines total GPU/CPU/Memory/Storage available for RHOAI workloads
#
# Quota Strategy (GPU-as-a-Service Demo):
#   - Standard workers: CPU/Memory/Storage for utility jobs
#   - 1x g6.4xlarge (1 GPU): Single-GPU inference
#   - 1x g6.12xlarge (4 GPUs): Tensor-parallel models
#
# IMPORTANT: GPU flavors must be in the SAME resourceGroup so Kueue can
# try both flavors when matching workloads.
apiVersion: kueue.x-k8s.io/v1beta1
kind: ClusterQueue
metadata:
  name: rhoai-main-queue
  annotations:
    argocd.argoproj.io/sync-wave: "4"
spec:
  # Allow any namespace with a LocalQueue to use this pool
  namespaceSelector: {}
  
  # Preemption policy - what happens when quota is exceeded
  preemption:
    reclaimWithinCohort: Any
    withinClusterQueue: LowerPriority
  
  # Flavor fungibility - try next flavor if first doesn't fit
  flavorFungibility:
    whenCanBorrow: Borrow
    whenCanPreempt: TryNextFlavor
  
  resourceGroups:
    # ═══════════════════════════════════════════════════════════════
    # Resource Group 1: Non-GPU workloads (utility jobs, uploads, etc.)
    # ═══════════════════════════════════════════════════════════════
    - coveredResources: ["cpu", "memory", "ephemeral-storage"]
      flavors:
        - name: default-worker
          resources:
            - name: "cpu"
              nominalQuota: "32"     # 32 vCPU for utility jobs
            - name: "memory"
              nominalQuota: "64Gi"   # 64GB RAM
            - name: "ephemeral-storage"
              nominalQuota: "500Gi"  # Disk for model downloads
    
    # ═══════════════════════════════════════════════════════════════
    # Resource Group 2: GPU workloads (inference, training)
    # Both flavors in same group for heterogeneous GPU scheduling
    # ═══════════════════════════════════════════════════════════════
    - coveredResources: ["nvidia.com/gpu", "cpu", "memory", "ephemeral-storage"]
      flavors:
        # 1-GPU flavor (g6.4xlarge nodes)
        - name: nvidia-l4-1gpu
          resources:
            - name: "nvidia.com/gpu"
              nominalQuota: 1       # 1 GPU from g6.4xlarge
            - name: "cpu"
              nominalQuota: "16"    # 16 vCPU
            - name: "memory"
              nominalQuota: "64Gi"  # 64GB RAM
            - name: "ephemeral-storage"
              nominalQuota: "200Gi" # Local disk
        # 4-GPU flavor (g6.12xlarge nodes)
        - name: nvidia-l4-4gpu
          resources:
            - name: "nvidia.com/gpu"
              nominalQuota: 4       # 4 GPUs from g6.12xlarge
            - name: "cpu"
              nominalQuota: "48"    # 48 vCPU
            - name: "memory"
              nominalQuota: "192Gi" # 192GB RAM
            - name: "ephemeral-storage"
              nominalQuota: "500Gi" # Local disk for large models
