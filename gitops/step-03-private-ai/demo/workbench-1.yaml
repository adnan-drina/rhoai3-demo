# Demo Workbench 1 - Gets the GPU first
# This workbench will be ADMITTED immediately if GPU is available
apiVersion: kubeflow.org/v1
kind: Notebook
metadata:
  name: demo-workbench-1
  namespace: private-ai
  labels:
    app: demo-workbench-1
    opendatahub.io/dashboard: "true"
    # Kueue queue assignment - uses private-ai-queue â†’ rhoai-main-queue (1 GPU quota)
    kueue.x-k8s.io/queue-name: "private-ai-queue"
  annotations:
    notebooks.opendatahub.io/inject-oauth: "true"
    opendatahub.io/username: "ai-developer"
    openshift.io/display-name: "Demo Workbench 1 (GPU)"
    openshift.io/description: "First workbench - should get GPU immediately"
spec:
  template:
    spec:
      containers:
        - name: demo-workbench-1
          image: image-registry.openshift-image-registry.svc:5000/redhat-ods-applications/pytorch:2025.1
          resources:
            limits:
              cpu: "4"
              memory: 16Gi
              nvidia.com/gpu: "1"
            requests:
              cpu: "2"
              memory: 8Gi
              nvidia.com/gpu: "1"
          ports:
            - containerPort: 8888
              name: notebook-port
              protocol: TCP
          volumeMounts:
            - name: workbench-data
              mountPath: /opt/app-root/src
            - name: demo-notebooks
              mountPath: /opt/app-root/src/demo
              readOnly: true
          env:
            - name: NOTEBOOK_ARGS
              value: "--NotebookApp.token='' --NotebookApp.password='' --NotebookApp.allow_origin='*'"
      # Target g6.4xlarge nodes (single L4 GPU)
      nodeSelector:
        node.kubernetes.io/instance-type: g6.4xlarge
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
      volumes:
        - name: workbench-data
          persistentVolumeClaim:
            claimName: demo-workbench-1-pvc
        - name: demo-notebooks
          configMap:
            name: gpu-demo-notebooks


